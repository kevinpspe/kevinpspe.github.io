[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "Welcome\nThis is a collection of resources and notes for political science and political economy methodology that I have collected throughout my postgraduate degree at the London School of Economics. I hope this resource can be useful to both myself and others!\nThe resources in this collection include:\n\nCausal inference, including details (and modern advancements) in difference-in-differences, regression discontinuity, and selection on observables.\nSome general content on statistical models.\n\nThe sidebar/menu contains parts. Each part contains an overview, and several follow-up pages regarding specific estimators/topics.\n\nNotation note: As with most causal inference notation, I will use capital letters to reference variables (such as treatment, outcome).\nI will use vectors/matrices for shortening regression equations. Because I am using capital letters to refer to variables, some vectors might be capitalised - which does not follow normal mathematical notation. Example: \\(\\b X_i\\) might be a vector of confounder values for unit \\(i\\).",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "correlation.html",
    "href": "correlation.html",
    "title": "Issue of Selection Bias",
    "section": "",
    "text": "This page covers how confounders cause pre-existing differences between treated and untreated (selection bias), meaning correlation is not causation.\n\nLet us look at this causal question:\n\n\n\n\n\n\n\n\nexample1\n\n\n\nD\n\nGoing to the Hospital (D)\n\n\n\nY\n\nHealth Outcomes (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\n\n\n\n\n\n\nWe have a treated group (went to hospital), and an untreated group. Using our potential outcomes framework, we can define the treatment effect of the treated group:\n\\[\n\\tau_\\text{treated} = \\textcolor{purple}{\\mean Y_{\\text{treated}}^{(1)}} - \\textcolor{red}{\\mean Y_{\\text{treated}}^{(0)}}\n\\]\n\nIn red is the counterfactual we do not observe.\n\nNow compare the treatment effects above to correlation, which is defined as the difference in observed outcomes:\n\\[\n\\begin{align}\n\\text{correlation} & = \\mean Y_\\text{treated} - \\mean Y_\\text{untreated} \\\\\n& = \\textcolor{purple}{\\mean Y_{\\text{treated}}^{(1)}} - \\textcolor{purple}{\\mean Y_\\text{untreated}^{(0)}}\n\\end{align}\n\\]\nIf we compare this correlation to our \\(\\tau_\\text{treated}\\), we see:\n\\[\n\\text{if  } \\textcolor{purple}{\\mean Y_\\text{untreated}^{(0)}} ≠ \\textcolor{red}{\\mean Y_\\text{treated}^{(0)}}, \\text{ then }  \\tau_\\text{treated} ≠ \\text{correlation}\n\\]\n\nThese two quantities are potential outcomes under control, or in another way to think of it, outcomes of the two groups prior to treatment happening.\n\nThus, if there is a difference between the average outcomes between treated and untreated before treatment is administered, then correlation is not equal to causation. This is because we cannot tell if the difference between the groups is due to treatment, or due to their pre-existing differences.\n\nWhat causes pre-existing differences? Confounders. For example, in our hospital-health example, a confounder could be smoking.\n\nSmoking is not the only possible confounder, we just use it as an example. Drinking, age, etc. are all other potential confounders.\n\nSmoking will worsen health outcomes. Someone who smokes is also more likely to visit the hospital with health complications. That means people who go to the hospital start out with (on average) worse health outcomes than people who did not go to the hospital.\n\n\n\n\n\n\n\n\nexample2\n\n\n\nD\n\nGoing to the Hospital (D)\n\n\n\nY\n\nHealth Outcomes (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\nX\n\nSmoking (Confounder)\n\n\n\nX-&gt;D\n\n\n\n\n\nX-&gt;Y\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA confounder is a third variable that has the following characteristics:\n\nThe confounder is correlated (positive or negative) with the outcome variable.\nThe confounder causes who gets and doesn’t get the treatment.\nThe confounder is not itself caused by the treatment\n\n\n\n\n\nNote requirement 3 - it is a common mistake. Any result of the treatment \\(D\\) cannot be a confounder.\n\nConfounders cause pre-existing differences, which cause correlation to not equal causation. We must account for confounders to uncover causal effects.",
    "crumbs": [
      "Causal Inference Basics",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue of Selection Bias</span>"
    ]
  },
  {
    "objectID": "randomisation.html",
    "href": "randomisation.html",
    "title": "The Magic of Randomisation",
    "section": "",
    "text": "This chapter covers how randomisation solves the problem of selection bias, and why randomisation is considered the “gold standard” of causal inference.\n\nLet us say we are interested in this question:\n\n\n\n\n\n\n\n\nexample1\n\n\n\nD\n\nScholarship (D)\n\n\n\nY\n\nUniversity Performance (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\n\n\n\n\n\n\nOur concern is a confounder. For example, smartness of an individual could mean they are more likely to get a scholarship. Since smart people tend to perform well at university, that means the people who get treated are different from those who don’t get treated.\n\n\n\n\n\n\n\n\nexample2\n\n\n\nD\n\nScholarship (D)\n\n\n\nY\n\nUniversity Performance (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\nX\n\nSmartness (Confounder)\n\n\n\nX-&gt;D\n\n\n\n\n\nX-&gt;Y\n\n\n\n\n\n\n\n\n\n\n\n\n\nSmartness is not the only confounder. Other confounders could be family income, athletic ability, etc.\n\nBut what if randomness (like flipping a coin) controls who gets the treatment or not. A coin will be flipped to decide if every person in our study will get the scholarship. This means that the randomness (the coin), and not the confounder, are causing selection into treatment:\n\n\n\n\n\n\n\n\nexample2\n\n\n\nD\n\nScholarship (D)\n\n\n\nY\n\nUniversity Performance (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\nX\n\nSmartness (Confounder)\n\n\n\nX-&gt;Y\n\n\n\n\n\n\nO\n\nCoin\n\n\n\nO-&gt;D\n\n\n\n\n\n\n\n\n\n\n\nSince the confounder is no longer causing who gets the treatment and who doesn’t, that means there is no more concern of selection bias.\n\nRandomisation also means that every individual has the same chance of being treated or untreated, so the two groups will, on average, the same as each other. That means:\n\\[\n\\textcolor{purple}{\\mean Y_\\text{untreated}^{(0)}} = \\textcolor{red}{\\mean Y_\\text{treated}^{(0)}}, \\text{ so correlation} = \\text{causation}\n\\]\n\nThis is established by the law of large numbers, but it is a little technical for here.\n\nSo if our treatment is randomly assigned (individuals randomly assigned to treatment or control), correlation does equal causation.\n\nRandomisation is the gold standard of causal inference. There is no better method.\n\nRandomisation is possible if you are running your own experiment: you can use a random number generator to assign treatment.\nRandomisation is also possible if there is something that is being randomly assigned in the real world. For example, the US green card lottery randomly chooses who gets accepted.\n\nHowever, randomisation is not always possible to due to cost of running experiments, non-compliance of individuals within experiments, and impracticality.\n\nNon-compliance is an issue that can be solved pretty easily with an instrumental variable, given a few assumptions about the non-compliance.",
    "crumbs": [
      "Causal Inference Basics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Magic of Randomisation</span>"
    ]
  },
  {
    "objectID": "did.html",
    "href": "did.html",
    "title": "Difference-in-Differences",
    "section": "",
    "text": "Coming soon",
    "crumbs": [
      "Difference-in-Differences"
    ]
  },
  {
    "objectID": "fuzzy.html",
    "href": "fuzzy.html",
    "title": "Fuzzy Discontinuity",
    "section": "",
    "text": "Fuzzy Regression Discontinuity is a design used when treatment is influenced, but not perfectly determined, by being above or below a cutoff.\n\n  Validity:  (3/5)\n\n\n  Interpretability:   (1/5)",
    "crumbs": [
      "Regression Discontinuity",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Fuzzy Discontinuity</span>"
    ]
  },
  {
    "objectID": "regress.html",
    "href": "regress.html",
    "title": "Fully Interacted Estimator",
    "section": "",
    "text": "See here on how selection on observables works, and the other estimators available.\n\nRegression is a natural way to control for confounders in selection on observables:\n\\[\nY_i = \\alpha + D_i\\tau + \\b X_i' \\b\\beta + \\eps_i\n\\]\n\nWhere \\(\\alpha\\) is the intercept and \\(\\b X_i\\) is a vector of confounder values for individual \\(i\\).\n\nThe ordinary least squares (OLS) estimate \\(\\hat\\tau\\) will be an good estimator of the ATE if we account for all confounders (conditional ignorability) in vector \\(\\b X_i\\), and there is no treatment heterogeneity.\n\nHeterogeneity means not all individuals have the same treatment effect. With heterogeneity, OLS is an estimator for an unhelpful combination of the ATT and ATU, not the ATE (Słoczyński, 2022).\n\nHeterogeneity is present in almost all situations we will need causal inference. Lin (2013) proposes the fully interacted estimator, which allows for consistent estimation of the ATE even with heterogeneity:\n\\[\nY_i = \\alpha + D_i \\tau + (\\b{X}_i - \\mean{\\b X})' \\b\\beta \\ + D_i (\\b X_i - \\mean{\\b X})' \\b\\gamma \\  + \\eps_i\n\\]\n\n\\(\\mean{\\b X}\\) is a vector of the means of each confounder. \\(\\tau\\) is the estimate of the ATE. See Lin (2013) for proofs.\n\n\n\n\n\n\n\n\nKevin’s Estimator Score:  (3/5)\n\nFully interacted estimator is decent at estimating the ATE, especially in large samples. We should be more careful in smaller samples.\nBig concern: the fully interacted estimator still assumes a linear relationship between confounders and the outcome. The other estimators covered later are non-parametric (not model based), so if we have any reason to suspect non-linearity, we should not use this estimator.\n\n\n\n\n\nBefore you implement the estimator, make sure you have reasons to believe you meet the neccessary assumptions for selection on observables.\nWe will need the estimatr package:\n\nlibrary(estimatr)\n\nThen, we can use the lm_lin() function to estimate:\n\nate &lt;- estimatr::lm_lin(Y ~ D,\n                        covariates = ~ X1 + X2 + X3,\n                        data = my_data)\nsummary(ate)\n\nThe output will be the ATE - the average treatment effect for all units in the study.",
    "crumbs": [
      "Selection on Observables",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fully Interacted Estimator</span>"
    ]
  },
  {
    "objectID": "distance.html",
    "href": "distance.html",
    "title": "Distance Matching",
    "section": "",
    "text": "See here on how selection on observables works, and the other estimators available.\n\nMia is in our study and receives the treatment. Mia’s causal effect is:\n\\[\n\\tau_{\\text{Mia}} = \\textcolor{purple}{Y^{(1)}_\\text{Mia}} - \\textcolor{red}{Y^{(0)}_\\text{Mia}}\n\\]\nWe cannot observe Mia’s counterfactual (in red). However, what we can do is to find an untreated individual similar to Mia to approximate Mia’s counterfactual:\n\\[\n\\tau_{\\text{Mia}} \\approx \\textcolor{purple}{Y^{(1)}_\\text{Mia}} - \\textcolor{purple}{Y^{(0)}_\\text{Matched individual}}\n\\]\nDistance matching matches an individual that is treated (like Mia) with one that is not treated based on how close their confounding values are. We define closeness by Mahalanobis distance:\n\\[\n\\delta_{i, j} = \\sqrt{(\\b x_i - \\b x_j)' \\ \\b\\Sigma_x^{-1} (\\b x_i - \\b x_j)}\n\\]\n\nWhere \\(i\\) and \\(j\\) are two units we want to measure the distance between, \\(\\b x\\) is a vector of confounder values, and \\(\\b\\Sigma_x\\) is the covariance matrix of confounders.\n\n\n\n\n\n\n\n\nKevin’s Estimator Score:  (2/5)\n\nDistance matching performs worse than genetic matching. However it is much quicker to estimate, so in larger datasets, you might consider to use distance matching.\nYou should not use distance matching on any dataset with more than 4 confounders, as it is badly biased by the curse of dimensionality.\nAll matching methods are data inefficient - they will throw out unmatched data, and this can greatly reduce our sample sizes.\nMatching is non-parametric, so it does not assume a linear relationship like regression.\n\n\n\n\n\nBefore you implement distance matching, make sure you have reasons to believe you meet the neccessary assumptions for selection on observables.\nWe will need the Matching package.\n\nlibrary(Matching)\n\nNow, we can implement the matching as follows.\n\natt &lt;- Match(Y = my_data$Y,\n             Tr = my_data$D,\n             X = my_data[,c(\"X1\",\"X2\", \"X3\")],\n             M = 1,\n             BiasAdjust = TRUE,\n             Weight = 2)\nsummary(att)\n\nOur output estimate will be the ATT - the average treatment effect for those units who received the treatment.",
    "crumbs": [
      "Selection on Observables",
      "Distance Matching"
    ]
  },
  {
    "objectID": "pscore.html",
    "href": "pscore.html",
    "title": "Propensity Score Matching",
    "section": "",
    "text": "See here on how selection on observables works, and the other estimators available.\n\nMia is in our study and receives the treatment. Mia’s causal effect is:\n\\[\n\\tau_{\\text{Mia}} = \\textcolor{purple}{Y^{(1)}_\\text{Mia}} - \\textcolor{red}{Y^{(0)}_\\text{Mia}}\n\\]\nWe cannot observe Mia’s counterfactual (in red). However, what we can do is to find an untreated individual similar to Mia to approximate Mia’s counterfactual:\n\\[\n\\tau_{\\text{Mia}} \\approx \\textcolor{purple}{Y^{(1)}_\\text{Mia}} - \\textcolor{purple}{Y^{(0)}_\\text{Matched individual}}\n\\]\nPropensity Score Matching matches an individual that is treated (like Mia) with one that is not treated based on how similar their likelihoods of treatment are.\nWhat is a likelihood of treatment? Well we know confounders cause people to get the treatment or not treatment. Thus, using an individual’s confounder values, we can estimate their likelihood of getting treatment, called a propensity score.\n\\[\n\\text{propensity score } \\pi =Pr(\\text{you get treated})\n\\]\n\nPropensity scores are typically estimated with a logistic regression, although in recent years, more researchers have started to use machine learning methods.\n\n\n\n\n\n\n\n\nKevin’s Estimator Score:  (2/5)\n\nPropensity score matching performs worse than genetic matching. However it is much quicker to estimate, so in larger datasets, you might consider to use distance matching.\nYou should not use propensity score matching on small datasets, as it can be badly biased, as the logistic regression used to estimate propensity scores relies on asymptotic consistency.\nAll matching methods are data inefficient - they will throw out unmatched data, and this can greatly reduce our sample sizes.\nMatching is non-parametric, so it does not assume a linear relationship like regression.\n\n\nThere are also some (advanced) criticisms of propensity score matching outlined here.\n\n\n\n\n\nBefore you implement propensity score matching, make sure you have reasons to believe you meet the neccessary assumptions for selection on observables:\nWe will need the Matching package.\n\nlibrary(Matching)\n\nFirst, we need to estimate the propensity scores with a logistic regression:\n\npropensity &lt;- glm(D ~ X1 + X2,\n                  data = my_data,\n                  family = \"binomial\")\nmy_data$pscore &lt;- predict(propensity,\n                          type = \"response\")\n\n\nA random forest model is also possible, but less common.\n\nNow, we can implement the matching as follows.\n\natt &lt;- Match(Y = my_data$Y,\n             Tr = my_data$D,\n             X = my_data[,\"pscore\"],\n             M = 1,\n             BiasAdjust = TRUE,\n             Weight = 2)\nsummary(att)\n\nOur output estimate will be the ATT - the average treatment effect for those units who received the treatment.",
    "crumbs": [
      "Selection on Observables",
      "Propensity Score Matching"
    ]
  },
  {
    "objectID": "genetic.html",
    "href": "genetic.html",
    "title": "Genetic Matching",
    "section": "",
    "text": "See here on how selection on observables works, and the other estimators available.\n\nMia is in our study and receives the treatment. Mia’s causal effect is:\n\\[\n\\tau_{\\text{Mia}} = \\textcolor{purple}{Y^{(1)}_\\text{Mia}} - \\textcolor{red}{Y^{(0)}_\\text{Mia}}\n\\]\nWe cannot observe Mia’s counterfactual (in red). However, what we can do is to find an untreated individual similar to Mia to approximate Mia’s counterfactual:\n\\[\n\\tau_{\\text{Mia}} \\approx \\textcolor{purple}{Y^{(1)}_\\text{Mia}} - \\textcolor{purple}{Y^{(0)}_\\text{Matched individual}}\n\\]\nLike distance matching, genetic matching matches an individual that is treated (like Mia) with one that is not treated based on how close their confounding values are. However, genetic matching uses a slightly different variation of mahalanobis distance:\n\\[\n\\delta_{i, j}(\\b W) = \\sqrt{(\\b x_i - \\b x_j)' \\ (\\b\\Sigma_x^{-\\frac{1}{2}})' \\ \\b W \\ \\b\\Sigma_x^{-\\frac{1}{2}}  (\\b x_i - \\b x_j)}\n\\]\n\nWhere \\(i\\) and \\(j\\) are two units we want to measure the distance between, \\(\\b x\\) are their confounder values, and \\(\\b\\Sigma_x\\) is the covariance matrix of confounders. \\(\\b W\\) is a weights matrix.\n\nThe weights \\(\\b W\\) are estimated to make the treated and untreated groups as similar as possible. Then, matching is done with the units that have the smallest distance.\n\n\n\n\n\n\n\nKevin’s Estimator Score:  (4/5)\n\nGenetic matching is the best performing matching estimator. However, genetic matching is also more computationally intensive, so for large data sets, propensity score matching might be quicker.\nAll matching methods are data inefficient - they will throw out unmatched data, and this can greatly reduce our sample sizes.\nMatching is non-parametric, so it does not assume a linear relationship like regression.\n\n\n\n\n\nBefore you start genetic matching, make sure you have reasons to believe you meet the neccessary assumptions for selection on observables:\nWe will need the Matching and MatchIt package.\n\nlibrary(Matching)\n\nFirst, we need to estimate the propensity scores with a logistic regression.\n\nIt is recommended to use the propensity score as one of the controls on which to genetic match on.\n\n\npropensity &lt;- glm(D ~ X1 + X2,\n                  data = my_data,\n                  family = \"binomial\")\nmy_data$pscore &lt;- predict(propensity,\n                          type = \"response\")\n\nThen, we use the GenMatch() function to estimate a weights matrix \\(\\b W\\):\n\nset.seed(333) #any number works\ngen &lt;- GenMatch(Tr = my_data$D,\n                    X = my_data[,c(\"X1\",\"X2\",\"pscore\")],\n                    BalanceMatrix = my_data[,c(\"X1\",\"X2\")],   \n                    estimand = \"ATT\",\n                    M = 2,\n                    replace = TRUE,\n                    ties = FALSE,\n                    distance.tolerance = 0,\n                    print.level = 0,\n                    pop.size = 200)\n\n\nYou can increase pop.size to increase the accuracy - but it will increase the time and computational power needed.\n\nNow, let us conduct estimation with genetic matching:\n\natt &lt;- Match(Y = my_data$Y,\n             Tr = my_data$D,\n             X = my_data[,c(\"X1\",\"X2\",\"pscore\")],\n             estimand = \"ATT\",\n             M = 2,\n             replace = TRUE,\n             ties = FALSE,\n             distance.tolerance = 0,\n             Weight.matrix = gen$Weight.matrix,\n             Weight = 3)\n\nOur output estimate will be the ATT - the average treatment effect for those units who received the treatment.",
    "crumbs": [
      "Selection on Observables",
      "Genetic Matching"
    ]
  },
  {
    "objectID": "weighting.html",
    "href": "weighting.html",
    "title": "Inverse Probability Weighting",
    "section": "",
    "text": "See here on how selection on observables works, and the other estimators available.\n\nLet us look at this example, with a confounder.\n\n\n\n\n\n\n\n\nexample2\n\n\n\nD\n\nReceiving Scholarship\n\n\n\nY\n\nUniversity Grades\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\nX\n\nSmartness (Confounder)\n\n\n\nX-&gt;D\n\n\n\n\n\nX-&gt;Y\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s pretend there are only dumb and smart people (for simplicity). Our treated and control groups might be:\n\n\n\n\n\n\n\nTreated (Got Scholarship)\nUntreated (Did not get scholarship)\n\n\nSmart Students (x4)\nSmart Students (x1)\n\n\nDumb Students (x1)\nDumb Students (x4)\n\n\n\nOur two groups have pre-existing differences. However, by emphasising certain individuals, we can make it seem like there are no more imbalances. For example, weighting might make our above table become:\n\n\n\n\n\n\n\nTreated (Got Scholarship)\nUntreated (Did not get scholarship)\n\n\nSmart Students (x4)\nSmart Students (emphasise to x4)\n\n\nDumb Students (emphasise to x4)\nDumb Students (x4)\n\n\n\n\nSee how the underrepresented individuals in each group (treated/untreated) were weighted upwards. More technically, inverse probability weighting emphasises/weights an individual by the inverse of their likelihood to receive treatment.\n\nWe can see there is no more pre-existing differences after weighting.\n\n\n\n\n\n\n\nKevin’s Estimator Score:  (3/5)\n\nWeighting is relatively good in large sample sizes.\nYou should not use weighting when with small samples, since their can be noticable bias, as the method is very sensitive to outlier propensity scores.\nWeighting is more efficient with data than matching as it does not throw out unmatched observations like matching estimators do.\nWeighting is non-parametric, so it does not assume a linear relationship like regression.\n\n\n\n\n\nBefore you inverse probability weighting, make sure you have reasons to believe you meet the neccessary assumptions for selection on observables:\nWe will need the estimatr package:\n\nlibrary(estimatr)\n\nTo estimate the propensity scores and weights, we can use the glm() command:\n\npropensity &lt;- glm(D ~ X1 + X2,\n                  data = my_data,\n                  family = \"binomial\")\nmy_data$pscore &lt;- predict(propensity, type = \"response\")\nmy_data$ipw &lt;- ifelse(mydata$D == 1,\n                      1/my_data$pscore,\n                      1/(1-my_data$pscore))\n\nFinally, we need to use the lm_robust() command to estimate our causal effects:\n\nate &lt;- estimatr::lm_robust(Y ~ D, data = my_data, weights = ipw)\nsummary(ate)\n\nThe output will be the ATE - the average treatment effect for all units in the study.",
    "crumbs": [
      "Selection on Observables",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Inverse Probability Weighting</span>"
    ]
  },
  {
    "objectID": "rdd.html",
    "href": "rdd.html",
    "title": "Regression Discontinuity",
    "section": "",
    "text": "Coming soon",
    "crumbs": [
      "Regression Discontinuity"
    ]
  },
  {
    "objectID": "frameworks.html",
    "href": "frameworks.html",
    "title": "Causal Inference Basics",
    "section": "",
    "text": "This page covers the potential outcomes framework and the causal estimands.\n\nIn causal inference, we are interested in causal questions:\n\n\n\n\n\n\n\n\nexample1\n\n\n\nD\n\nTreatment (D)\n\n\n\nY\n\nOutcome (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\n\n\n\n\n\n\n\nWe generally assume the treatment \\(D\\) is binary.\n\nImagine we have two hypothetical parallel worlds that are copies of each other. Both of these worlds are identical except for one aspect: the treatment:\n\n\n\n\n\n\n\n\nParallel World\nTreatment\nPotential Outcome\n\n\nKevin does not Receive Treatment\n\\(D_\\text{Kevin} = 0\\)\n\\(\\purple{Y_\\text{Kevin}^{(0)}}\\)\n\n\nKevin Receives Treatment\n\\(D_\\text{Kevin} = 1\\)\n\\(\\purple{Y_\\text{Kevin}^{(1)}}\\)\n\n\n\n\nThe only difference between the two worlds is the treatment. Thus, any difference in outcomes between the two worlds must be the causal effect of the treatment.\n\\[\n\\tau_\\text{Kevin} = \\purple{Y_\\text{Kevin}^{(1)}} - \\purple{Y_\\text{Kevin}^{(0)}}\n\\]\n\nTechnically, we need another assumption, SUTVA, for this to be true. I will explain this assumption as part of the identification assumptions.\n\nHowever, in reality, we do not have two parallel worlds. Thus, by definition, one of the potential outcomes is not observed in our real world - the counterfactual.\n\n\n\n\n\n\n\n\nIn the Real World\nObserved Outcome\nCounterfactual\n\n\nKevin receives treatment (treated)\n\\(Y_\\text{Kevin}= \\purple{Y_\\text{Kevin}^{(1)}}\\)\n\\(\\red{Y_\\text{Kevin}^{(0)}}\\)\n\n\nKevin did not receive treatment (untreated)\n\\(Y_\\text{Kevin} = \\purple{Y_\\text{Kevin}^{(0)}}\\)\n\\(\\red{Y_\\text{Kevin}^{(1)}}\\)\n\n\n\n\nThe fundamental problem of causal inference is that in order to calculate our individual treatment effect \\(\\tau\\), we need both potential outcomes. Our goal is to estimate causal effects without observing counterfactuals. This is difficult at the individual level, so instead, we focus on average treatment effects for groups:\n\n\n\n\n\n\n\n\nGroup Effects\nNotation\nDefinition\n\n\nAverage Treatment Effect (ATE)\n\\(\\tau_\\text{ATE}\\)\nThe average treatment effects for all individuals in our study (treated and untreated).\n\n\nAverage Treatment Effect on the Treated (ATT)\n\\(\\tau_\\text{ATT}\\)\nThe average treatment effect but only for individuals who receive the treatment in our study.\n\n\nLocal Average Treatment Effect (LATE)\n\\(\\tau_\\text{LATE}\\)\nThe average treatment effect but only for a specific (local) group of individuals in a study.",
    "crumbs": [
      "Causal Inference Basics"
    ]
  },
  {
    "objectID": "soo.html",
    "href": "soo.html",
    "title": "Selection on Observables",
    "section": "",
    "text": "This is an overview of selection on observables. For estimators and R-code, use the sidebar.\n\nOur issue in causal inference is that a confounder is causing pre-existing differences:\n\n\n\n\n\n\n\n\nexample2\n\n\n\nD\n\nReceiving Scholarship\n\n\n\nY\n\nUniversity Grades\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\nX\n\nIntellegence (Confounder)\n\n\n\nX-&gt;D\n\n\n\n\n\nX-&gt;Y\n\n\n\n\n\n\n\n\n\n\n\n\nBy definition, as the confounder changes, your likelihood of getting treatment changes. As the confounder changes, the outcome value will also change.\nThese issues occur when the confounder changes in value. So what if we hold the confounders constant? Let’s assume that intellegence has two values: smart and dumb. Let us calculate the treatment effect within each level of intellegence:\n\\[\n\\tau_\\text{smart} = \\purple{\\mean Y_\\text{smart}^{(1)}} - \\purple{\\mean Y_\\text{smart}^{(0)}}\n, \\quad \\tau_\\text{dumb} = \\purple{\\mean Y_\\text{dumb}^{(1)}} - \\purple{\\mean Y_\\text{dumb}^{(0)}}\n\\]\n\nObviously, most confounders will not have only 2 values. But the same intuition applies - for each value of confounders, we split all individuals into groups, and calculate the average treatment effect within each group.\n\nThe confounder is constant here, so no selection bias. Thus, within each category, correlation is equal to causation. Our overall causal effect will be a weighted average of the categories:\n\\[\n\\tau = \\tau_\\text{smart} Pr(\\text{smart})  \\ + \\ \\tau_\\text{dumb} Pr(\\text{dumb})\n\\]\n\nThe weights of this weighted average are the probability/frequency of that value of the confounder.\n\nFor selection on observables to work, we need to meet 3 assumptions:\n\n\n\n\n\n\n\nAssumption\nDescription\n\n\nConditional Ignorability\nThis means that we must account for all possible confounders (cannot miss a single one).\n\n\nCommon Support\nThis means no one can have a 100% chance of being in treatment or control. They always have a chance to be in either, no matter their confounding values.\n\n\nStable Unit Treatment Value Assumption (SUTVA)\nThis means that if Ava is treated, that does not affect Mia’s outcome (and for any other 2 individuals).\n\n\n\n\nWe have a wide choice of estimators that we can use.\n\n\n\n\n\n\n\nEstimator\nKevin’s Rating\n\n\nFully Interacted Estimator\n\n\n\n\n\nDistance Matching\n\n\n\n\n\nPropensity Score Matching\n\n\n\n\n\nGenetic Matching\n\n\n\n\n\nInverse Probability Weighting\n\n\n\n\n\n\n\nImportant: You should not always go for the higher rated estimator. Each estimator has its strengths/weaknesses, which the links for each page explain in more detail.\n\nUse the sidebar or links in the table to access each estimator’s page.",
    "crumbs": [
      "Selection on Observables"
    ]
  }
]