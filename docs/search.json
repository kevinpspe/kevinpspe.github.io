[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kevin’s PSPE Resources",
    "section": "",
    "text": "Welcome\n\n\n\n\n\nThis is a collection of resources and notes for political science and political economy that I have collected throughout my postgraduate degree at the London School of Economics\nMost of these resources relate around causal inference, statistics, and game theory.\nI am continuously adding more to this collection as a learn more. Some parts may be incomplete, and you may see some changes in existing parts.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "frameworks.html",
    "href": "frameworks.html",
    "title": "Potential Outcomes",
    "section": "",
    "text": "In causal inference, we are concerned with how a treatment (notated \\(D\\)) causes some change in the outcome variable (notated \\(Y\\)).\nImagine we have two hypothetical parallel worlds that are copies of each other. Both of these worlds are identical except for one aspect: the treatment. In one world, you get the treatment, and in the other parallel world, you do not get the treatment:\n\n\n\n\n\n\n\n\n\n\nParallel World\nPotential Outcome\n\n\n\n\nIndividual \\(i\\) Does not Receive Treatment: \\(D_i = 0\\)\n\\(\\C\\)\n\n\nIndividual \\(i\\) Receives Treatment: \\(D_i = 1\\)\n\\(\\T\\)\n\n\n\n\n\nTable 1.1: The (0) and (1) are not exponents - they label the outcome \\(Y\\) for treatment status.\n\n\n\nThe two hypothetical parallel worlds are identical to each other, with the only difference being in one world, you get the treatment. Thus, any difference in outcomes between the two worlds must be the causal effect of the treatment:\n\\[\n\\tau_i = \\T - \\C\n\\]\n\n\nTechnically, this is only true if SUTVA is met.\n\nHowever, in reality, we do not have two parallel worlds. You either get the treatment, or don’t get the treatment. Thus, by definition, one of the potential outcomes is not observed in our real world - the one not observed is called the counterfactual.\n\n\n\n\n\n\n\n\n\n\n\nIn the Real World\nObserved Outcome \\(Y\\)\nCounterfactual\n\n\n\n\nScenario 1: \\(i\\) receives treatment\n\\(Y_i = \\T\\)\n\\(\\Cred\\)\n\n\nScenario 2: \\(i\\) did not receive treatment\n\\(Y_i = \\C\\)\n\\(\\Tred\\)\n\n\n\n\n\nTable 1.2: From now on, I will always label counterfactuals in red.\n\n\n\nThe fundamental problem of causal inference is that in order to calculate our individual treatment effect \\(\\tau\\), we need both potential outcomes. However, we can never observe both.\n\nTo find the causal effect, we need to estimate the counterfactuals with an estimator. This is difficult at the individual level, so instead, we focus on average treatment effects for groups. There are three main group causal effects:\n\n\n\n\n\n\n\n\n\n\n\nGroup Effects\nNotation\nDefinition\n\n\n\n\nAverage Treatment Effect (ATE)\n\\(\\tau_\\text{ATE}\\)\nThe average of individual treatment effects \\(\\tau\\), for all individuals in our study, including people who did and didn’t get the treatment.\n\n\nAverage Treatment Effect on the Treated (ATT)\n\\(\\tau_\\text{ATT}\\)\nThe average of individual treatment effects \\(\\tau\\), but only for individuals who receive the treatment in our study. We ignore those who never receive treatment in our study.\n\n\nLocal Average Treatment Effect (LATE)\n\\(\\tau_\\text{LATE}\\)\nThe average of individual treatment effects \\(\\tau\\), but only for a specific (local) group of individuals in a study. This group is usually defined by some characteristic the individuals hold together.\n\n\n\n\n\nTable 1.3: These are called estimands.",
    "crumbs": [
      "Basics of Causal Inference",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Potential Outcomes</span>"
    ]
  },
  {
    "objectID": "frameworks.html#causal-questions-treatment-and-outcomes",
    "href": "frameworks.html#causal-questions-treatment-and-outcomes",
    "title": "Basics of Causation",
    "section": "",
    "text": "Our Causal Question: \\(D \\rightarrow Y\\)\nTreatment \\(D\\)\nOutcome \\(Y\\)\n\n\n\n\nHow does taking the vaccine cause change in mortality rates?\nGetting the vaccine (yes or no)\nMortality rate\n\n\nHow does going to college change your expected lifetime earnings?\nWent to college (yes or no)\nExpected lifetime earnings\n\n\nHow does the presence of tax exemptions on electric vehicles change how many electric vehicles are sold?\nTax exemptions on electric vehicles (yes or no)\nAmount of electric vehicles sold\n\n\n\n\n\nTable 1.1: Examples of causal questions.\n\n\n\n\n\n\n\nNote: binary is a variable that can only take two values. For example, flipping a coin is either heads or tails.",
    "crumbs": [
      "Basics of Causal Inference",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of Causation</span>"
    ]
  },
  {
    "objectID": "frameworks.html#understanding-causation-through-potential-outcomes",
    "href": "frameworks.html#understanding-causation-through-potential-outcomes",
    "title": "Basics of Causation",
    "section": "Understanding Causation through Potential Outcomes",
    "text": "Understanding Causation through Potential Outcomes\nImagine we have two hypothetical parallel worlds that are copies of each other. Both of these worlds are identical except for one aspect: the treatment. In one world, you get the treatment, and in the other parallel world, you do not get the treatment.\nThe outcome values of these two parallel worlds are called potential outcomes:\n\n\n\n\n\n\n\n\n\n\nParallel World\nPotential Outcome\n\n\n\n\nDoes not Receive Treatment: \\(D = 0\\)\n\\(\\C\\)\n\n\nReceives Treatment: \\(D = 1\\)\n\\(\\T\\)\n\n\n\n\n\nTable 1.2: The (0) and (1) are not exponents - they label the outcome \\(Y\\) for treatment status.\n\n\n\nThe two hypothetical parallel worlds are identical to each other, with the only difference being in one world, you get the treatment. Thus, any difference in outcomes between the two worlds must be the causal effect of the treatment (notated \\(\\tau\\)):\n\\[\n\\tau = \\T - \\C\n\\]\n\n\nNote: For this to be the causal effect, we need an additional assumption, SUTVA. See appendix B.\nWe call this causal effect the individual treatment effect.",
    "crumbs": [
      "Basics of Causal Inference",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of Causation</span>"
    ]
  },
  {
    "objectID": "frameworks.html#the-problem-of-counterfactuals",
    "href": "frameworks.html#the-problem-of-counterfactuals",
    "title": "Basics of Causation",
    "section": "The Problem of Counterfactuals",
    "text": "The Problem of Counterfactuals\nHowever, in reality, we do not have two parallel worlds. You either get the treatment, or don’t get the treatment. Thus, by definition, one of the potential outcomes is not observed in our real world - the one not observed is called the counterfactual.\n\n\n\n\n\n\n\n\n\n\n\nIn the Real World\nObserved Outcome \\(Y\\)\nCounterfactual\n\n\n\n\nScenario 1: I receive treatment\n\\(Y = \\T\\)\n\\(\\Cred\\)\n\n\nScenario 2: I did not receive treatment\n\\(Y = \\C\\)\n\\(\\Tred\\)\n\n\n\n\n\nTable 1.2: From now on, I will always label counterfactuals in red.\n\n\n\nThe fundamental problem of causal inference is that in order to calculate our individual treatment effect \\(\\tau\\), we need both potential outcomes. However, we can never observe both.\nTo find the causal effect, we need to estimate the counterfactuals with an estimator. This is difficult at the individual level, so instead, we focus on average treatment effects for groups. There are three main group causal effects:\n\n\n\n\n\n\n\n\n\n\n\nGroup Effects\nNotation\nDefinition\n\n\n\n\nAverage Treatment Effect (ATE)\n\\(\\tau_\\text{ATE}\\)\nThe average of individual treatment effects \\(\\tau\\), for all individuals in our study, including people who did and didn’t get the treatment.\n\n\nAverage Treatment Effect on the Treated (ATT)\n\\(\\tau_\\text{ATT}\\)\nThe average of individual treatment effects \\(\\tau\\), but only for individuals who receive the treatment in our study. We ignore those who never receive treatment in our study.\n\n\nLocal Average Treatment Effect (LATE)\n\\(\\tau_\\text{LATE}\\)\nThe average of individual treatment effects \\(\\tau\\), but only for a specific (local) group of individuals in a study. This group is usually defined by some characteristic the individuals hold together.\n\n\n\n\n\nTable 1.3: For a formal definition of these quantities, see appendix B.",
    "crumbs": [
      "Basics of Causal Inference",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of Causation</span>"
    ]
  },
  {
    "objectID": "correlation.html",
    "href": "correlation.html",
    "title": "Issue of Selection Bias",
    "section": "",
    "text": "Let us look at this causal question:\n\n\n\n\n\n\n\n\nexample1\n\n\n\nD\n\nGoing to the Hospital (D)\n\n\n\nY\n\nHealth Outcomes (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\n\n\n\n\n\n\nIf we just collect correlation data, we likely find the following:\n\nThe average health of individuals who got hospital treatment is low.\nThe average health of individuals who did not get hospital treatment is high.\nThus, we find that hospital treatment is correlated with worse health outcomes.\n\nBut does that mean hospital treatment causes worse health outcomes? No! The reason we have a negative correlation is because the people who get treated, and the people who do not get treated, are different before the treatment.\n\nLess healthy people are more likely to go to the hospital to get treated in the first place. That means before the hospital even begins treatment, there are pre-existing differences between people getting treatment and people that are untreated.\n\nThus, we cannot tell if the difference in health outcomes between treated and untreated is due to the treatment, or due to their pre-existing differences.\n\nWe can illustrate the same point using potential outcomes from last chapter:\n\n\n\n\n\n\n\n\n\n\n\n\nTreated\nUntreated\n\n\n\n\nObserved \\(\\mean Y\\)\n\\(\\mean Y_\\text{treated} = \\textcolor{purple}{\\mean Y_{\\text{treated}}^{(1)}}\\)\n\\(\\mean Y_\\text{untreated} = \\textcolor{purple}{\\mean Y_{\\text{untreated}}^{(0)}}\\)\n\n\nCounterfactual\n\\(\\textcolor{red}{\\mean Y_{\\text{treated}}^{(0)}}\\)\n\\(\\textcolor{red}{\\mean Y_{\\text{untreated}}^{(1)}}\\)\n\n\nReal Treatment Effect\n\\(\\textcolor{purple}{\\mean Y_{\\text{treated}}^{(1)}} - \\textcolor{red}{\\mean Y_{\\text{treated}}^{(0)}}\\)\n\\(\\textcolor{red}{\\mean Y_{\\text{untreated}}^{(1)}} - \\textcolor{purple}{\\mean Y_{\\text{untreated}}^{(0)}}\\)\n\n\n\n\n\nTable 2.1: This table uses what we learned about counterfactuals (Table 1.2) and treatment effects.\n\n\n\nWe see the real treatment effects. But how do these treatment effects compare to correlation:\n\\[\n\\begin{align}\n\\text{correlation} & = \\mean Y_\\text{treated} - \\mean Y_\\text{untreated} \\\\\n& = \\textcolor{purple}{\\mean Y_{\\text{treated}}^{(1)}} - \\textcolor{purple}{\\mean Y_\\text{untreated}^{(0)}}\n\\end{align}\n\\]\n\n\nCorrelation is the difference in observed outcomes.\nIf we compare this correlation equation to our treatment effects, in our table, we see:\n\\[\n\\text{if  } \\textcolor{purple}{\\mean Y_\\text{untreated}^{(0)}} ≠ \\textcolor{red}{\\mean Y_\\text{treated}^{(0)}}, \\text{ then correlation} ≠ \\text{causation}\n\\]\n\nWhat are these two values? They are the average potential outcomes of each group (treatment and control), in the parallel world of not recieving the treatment.\nOr we can think of it as the average outcomes before treatment.\n\nThus, if there is a difference between the average outcomes between treated and untreated before treatment is administered, then correlation is not equal to causation.\n\nA confounder is a third variable that has the following characteristics:\n\nThe confounder is correlated (positive or negative) with the outcome variable.\nThe confounder causes who gets and doesn’t get the treatment.\nThe confounder is not itself caused by the treatment.\n\nA confounder will cause some people to get the treatment, and others to not get the treatment. A confounder is also correlated with the outcome.\nThese two facts mean that before we even start the treatment, people who will get the treatment differ from people who will not get the treatment.\nThus, confounders cause selection bias and pre-existing differences.\n\nFor example, in our hospital-health example, a confounder could be smoking.\n\nSmoking will worsen health outcomes. Someone who smokes is also more likely to visit the hospital with health complications.\nThat means people who go to the hospital start out with (on average) worse health outcomes than people who did not go to the hospital.\n\n\n\nNote: smoking is not the only possible confounder, we just use it as an example. Drinking, age, etc. are all other potential confounders.\n\n\n\n\n\n\n\n\nexample2\n\n\n\nD\n\nGoing to the Hospital (D)\n\n\n\nY\n\nHealth Outcomes (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\nX\n\nSmoking (Confounder)\n\n\n\nX-&gt;D\n\n\n\n\n\nX-&gt;Y\n\n\n\n\n\n\n\n\n\n\n\n\nThis means that the treated group has more smokers and people with bad health than the untreated group. This pre-existing difference between treated and untreated means correlation is not equal to causation.",
    "crumbs": [
      "Basics of Causal Inference",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Issue of Selection Bias</span>"
    ]
  },
  {
    "objectID": "correlation.html#what-is-correlation",
    "href": "correlation.html#what-is-correlation",
    "title": "Correlation vs. Causation",
    "section": "",
    "text": "Find the average outcome \\(Y\\) of those who receive the treatment: \\(\\mean Y_\\text{treated}\\).\nFind the average outcome \\(Y\\) values those who do not get the treatment: \\(\\mean Y_\\text{untreated}\\).\n\n\n\nNote: the bar/line over the \\(Y\\) is the statistical symbol for mean/average.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType of Correlation\nInterpretation\n\n\n\n\nPositive Correlation between treatment and outcome.\nGetting the treatment is related with higher outcome values on average.\n\n\nNegative Correlation between treatment and outcome.\nGetting the treatment is related with lower outcome values on average.\n\n\nNo (Zero) Correlation between treatment and outcome.\nGetting the treatment has no relationship with the average outcome values.\n\n\n\n\n\nTable 2.1: Note how I used the world related - correlation is not causation.",
    "crumbs": [
      "Basics of Causal Inference",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Correlation vs. Causation</span>"
    ]
  },
  {
    "objectID": "correlation.html#why-correlation-is-not-causation-selection-bias",
    "href": "correlation.html#why-correlation-is-not-causation-selection-bias",
    "title": "Correlation vs. Causation",
    "section": "Why Correlation is not Causation: Selection Bias",
    "text": "Why Correlation is not Causation: Selection Bias\nLet us look at this causal question:\n\n\n\n\n\n\n\n\nexample1\n\n\n\nD\n\nGoing to the Hospital (D)\n\n\n\nY\n\nHealth Outcomes (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\n\n\n\n\n\n\nIf we just collect correlation data, we likely find the following:\n\nThe average health of individuals who got hospital treatment is low.\nThe average health of individuals who did not get hospital treatment is high.\nThus, we find that hospital treatment is correlated with worse health outcomes.\n\nBut does that mean hospital treatment causes worse health outcomes? No! The reason we have a negative correlation is because the people who get treated, and the people who do not get treated, are different before the treatment.\n\nLess healthy people are more likely to go to the hospital to get treated in the first place. That means before the hospital even begins treatment, there are pre-existing differences between people getting treatment and people that are untreated.\n\nThus, we cannot tell if the difference in health outcomes between treated and untreated is due to the treatment, or due to their pre-existing differences.\nWe can illustrate the same point using potential outcomes from last chapter:\n\n\n\n\n\n\n\n\n\n\n\n\nTreated\nUntreated\n\n\n\n\nObserved \\(\\mean Y\\)\n\\(\\mean Y_\\text{treated} = \\textcolor{purple}{\\mean Y_{\\text{treated}}^{(1)}}\\)\n\\(\\mean Y_\\text{untreated} = \\textcolor{purple}{\\mean Y_{\\text{untreated}}^{(0)}}\\)\n\n\nCounterfactual\n\\(\\textcolor{red}{\\mean Y_{\\text{treated}}^{(0)}}\\)\n\\(\\textcolor{red}{\\mean Y_{\\text{untreated}}^{(1)}}\\)\n\n\nReal Treatment Effect\n\\(\\textcolor{purple}{\\mean Y_{\\text{treated}}^{(1)}} - \\textcolor{red}{\\mean Y_{\\text{treated}}^{(0)}}\\)\n\\(\\textcolor{red}{\\mean Y_{\\text{untreated}}^{(1)}} - \\textcolor{purple}{\\mean Y_{\\text{untreated}}^{(0)}}\\)\n\n\n\n\n\nTable 2.2: This table uses what we learned about counterfactuals (Table 1.3) and treatment effects.\n\n\n\nWe see the real treatment effects. But how do these treatment effects compare to correlation? Recall our definition of correlation:\n\\[\n\\begin{align}\n\\text{correlation} & = \\mean Y_\\text{treated} - \\mean Y_\\text{untreated} \\\\\n& = \\textcolor{purple}{\\mean Y_{\\text{treated}}^{(1)}} - \\textcolor{purple}{\\mean Y_\\text{untreated}^{(0)}}\n\\end{align}\n\\]\nIf we compare this correlation equation to our treatment effects, in our table, we see:\n\\[\n\\text{if  } \\textcolor{purple}{\\mean Y_\\text{untreated}^{(0)}} ≠ \\textcolor{red}{\\mean Y_\\text{treated}^{(0)}}, \\text{ then correlation} ≠ \\text{causation}\n\\]\n\nWhat are these two values? They are the average potential outcomes of each group (treatment and control), in the parallel world of not recieving the treatment.\nOr we can think of it as the average outcomes before treatment.\n\nThus, if there is a difference between the average outcomes between treated and untreated before treatment is administered, then correlation is not equal to causation.\n\n\nNote: for details on selection bias, see appendix B.",
    "crumbs": [
      "Basics of Causal Inference",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Correlation vs. Causation</span>"
    ]
  },
  {
    "objectID": "correlation.html#confounders-and-the-cause-of-selection-bias",
    "href": "correlation.html#confounders-and-the-cause-of-selection-bias",
    "title": "Correlation vs. Causation",
    "section": "Confounders and the Cause of Selection Bias",
    "text": "Confounders and the Cause of Selection Bias\nA confounder is a third variable that has the following characteristics:\n\nThe confounder is correlated (positive or negative) with the outcome variable.\nThe confounder causes who gets and doesn’t get the treatment.\nThe confounder is not itself caused by the treatment.\n\nA confounder will cause some people to get the treatment, and others to not get the treatment. A confounder is also correlated with the outcome.\nThese two facts mean that before we even start the treatment, people who will get the treatment differ from people who will not get the treatment.\nThus, confounders cause selection bias and pre-existing differences.\nFor example, in our hospital-health example, a confounder could be smoking.\n\nSmoking will worsen health outcomes. Someone who smokes is also more likely to visit the hospital with health complications.\nThat means people who go to the hospital start out with (on average) worse health outcomes than people who did not go to the hospital.\n\n\n\nNote: smoking is not the only possible confounder, we just use it as an example. Drinking, age, etc. are all other potential confounders.\n\n\n\n\n\n\n\n\nexample2\n\n\n\nD\n\nGoing to the Hospital (D)\n\n\n\nY\n\nHealth Outcomes (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\nX\n\nSmoking (Confounder)\n\n\n\nX-&gt;D\n\n\n\n\n\nX-&gt;Y\n\n\n\n\n\n\n\n\n\n\n\n\nThis means that the treated group has more smokers and people with bad health than the untreated group. This pre-existing difference between treated and untreated means correlation is not equal to causation.\nSo we now know that correlation is not equal to causation, because confounders cause selection bias. Thus, if we have a correlation, and we want to find the causal effect, we have to eliminate the influence of confounders, which will eliminate the reason correlation does not equal causation.\nThus, researchers need to employ research designs that can eliminate the errors caused by confounders, and identify the causal effect. The rest of this book explores these research designs.",
    "crumbs": [
      "Basics of Causal Inference",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Correlation vs. Causation</span>"
    ]
  },
  {
    "objectID": "randomisation.html",
    "href": "randomisation.html",
    "title": "The Magic of Randomisation",
    "section": "",
    "text": "Let us say we are interested in this question:\n\n\n\n\n\n\n\n\nexample1\n\n\n\nD\n\nScholarship (D)\n\n\n\nY\n\nUniversity Performance (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\n\n\n\n\n\n\nOur concern is a confounder. For example, smartness of an individual could mean they are more likely to get a scholarship. Since smart people tend to perform well at university, that means the people who get treated are, on average, different from those who don’t get treated.\n\n\nNote: smartness is not the only confounder. Other confounders could be family income, athletic ability, etc.\n\n\n\n\n\n\n\n\nexample2\n\n\n\nD\n\nScholarship (D)\n\n\n\nY\n\nUniversity Performance (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\nX\n\nSmartness (Confounder)\n\n\n\nX-&gt;D\n\n\n\n\n\nX-&gt;Y\n\n\n\n\n\n\n\n\n\n\n\n\nThe key here is that the confounder is influencing who gets and doesn’t get the treatment.\n\nBut what if randomness (like flipping a coin) controls who gets the treatment or not. A coin will be flipped to decide if every person in our study will get the scholarship.\nThis means that the randomness (the coin), and not the confounder, are causing selection into treatment. So now, we have this diagram:\n\n\n\n\n\n\n\n\nexample2\n\n\n\nD\n\nScholarship (D)\n\n\n\nY\n\nUniversity Performance (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\nX\n\nSmartness (Confounder)\n\n\n\nX-&gt;Y\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote how the confounder now no longer has an arrow to the treatment. It is no longer causing who gets the treatment or not.\nSince the confounder is no longer causing who gets the treatment and who doesn’t, that means there is no more concern of selection bias.\n\nRandomisation also means that since every individual has the same chance of entering treatment or control, that these two groups will be, on average, the same as each other. That means:\n\\[\n\\textcolor{purple}{\\mean Y_\\text{untreated}^{(0)}} = \\textcolor{red}{\\mean Y_\\text{treated}^{(0)}}, \\text{ so correlation} = \\text{causation}\n\\]\n\n\nThis equation is taken from the last chapter.\nSo if our treatment is randomly assigned (individuals randomly assigned to treatment or control), correlation does equal causation.\n\nWhen should you use randomisation? The answer is whenever possible. Randomisation is the gold standard of causal inference. There is no better method.\n\nRandomisation is possible if you are running your own experiment: you can use a random number generator to assign treatment.\nRandomisation is also possible if there is something that is being randomly assigned in the real world. For example, the US green card lottery randomly chooses who gets accepted.\n\n\nHowever, randomisation is not always possible to do for a variety of reasons.\n\nCost: Randomisation often involves running your own experiment.\nImpracticality: Sometimes it just is impossible to randomly assign certain treatments. For example, you cannot assign countries to be dictatorships in order to test the causal effect.\nNon-Compliance: Maybe you assign people randomly to treatment or control. But what if they don’t comply with their assignment? Perhaps there is some confounder that means someone is more likely to not comply? To solve this, you will need to use instrumental variables.",
    "crumbs": [
      "Basics of Causal Inference",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Magic of Randomisation</span>"
    ]
  },
  {
    "objectID": "randomisation.html#what-is-randomisation",
    "href": "randomisation.html#what-is-randomisation",
    "title": "The Magic of Randomisation",
    "section": "",
    "text": "example1\n\n\n\nD\n\nScholarship (D)\n\n\n\nY\n\nUniversity Performance (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\n\n\n\n\n\n\n\n\n\nNote: smartness is not the only confounder. Other confounders could be family income, athletic ability, etc.\n\n\n\n\n\n\n\n\nexample2\n\n\n\nD\n\nScholarship (D)\n\n\n\nY\n\nUniversity Performance (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\nX\n\nSmartness (Confounder)\n\n\n\nX-&gt;D\n\n\n\n\n\nX-&gt;Y\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexample2\n\n\n\nD\n\nScholarship (D)\n\n\n\nY\n\nUniversity Performance (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\nX\n\nSmartness (Confounder)\n\n\n\nX-&gt;Y\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote how the confounder now no longer has an arrow to the treatment. It is no longer causing who gets the treatment or not.\n\n\n\n\n\nThis equation is taken from the last chapter.",
    "crumbs": [
      "Basics of Causal Inference",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Magic of Randomisation</span>"
    ]
  },
  {
    "objectID": "randomisation.html#limitations-of-randomisation",
    "href": "randomisation.html#limitations-of-randomisation",
    "title": "The Magic of Randomisation",
    "section": "Limitations of Randomisation",
    "text": "Limitations of Randomisation\nWhen should you use randomisation? The answer is whenever possible. Randomisation is the gold standard of causal inference. There is no better method.\n\nRandomisation is possible if you are running your own experiment: you can use a random number generator to assign treatment.\nRandomisation is also possible if there is something that is being randomly assigned in the real world. For example, the US green card lottery randomly chooses who gets accepted.\n\nHowever, randomisation is not always possible to do for a variety of reasons.\n\nCost: Randomisation often involves running your own experiment.\nImpracticality: Sometimes it just is impossible to randomly assign certain treatments. For example, you cannot assign countries to be dictatorships in order to test the causal effect.\nNon-Compliance: Maybe you assign people randomly to treatment or control. But what if they don’t comply with their assignment? Perhaps there is some confounder that means someone is more likely to not comply? To solve this, you will need to use instrumental variables.",
    "crumbs": [
      "Basics of Causal Inference",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Magic of Randomisation</span>"
    ]
  },
  {
    "objectID": "randomisation.html#statistical-inference-and-uncertainty",
    "href": "randomisation.html#statistical-inference-and-uncertainty",
    "title": "The Magic of Randomisation",
    "section": "Statistical Inference and Uncertainty",
    "text": "Statistical Inference and Uncertainty\nEven though with randomisation, correlation is equal to causation, there is still some uncertainty in our causal effect. Why?\nImagine you are running a random experiment multiple times.\n\nFirst time, you assign everyone to treatment or untreated randomly, then calculate the average difference between treatment and untreated.\nThen you do the same thing again. Randomly assign everyone to treatment or untreated. However, because you are doing this randomly, your treatment and untreated groups will be slightly different than from the first time. Thus, your average difference between treatment and untreated will be slightly different.\nEvery time you re-run the experiment, you will get a slightly different result.\n\nSo which result is correct? Well, what we can do is plot all of our average/mean causal effects on the horizontal axis, with vertical bars showing how often we get each result:\n\n\n\n\n\n\n\nThe higher the bar, the more frequently we got that causal estimate (mean/average difference between treatment and control).\nThis graph is called the sampling distribution, and is a visualisation of the uncertainty in each of our causal estimates. If you just run one experiment, you could get any one of those results.\nThus, our causal estimation process has a level of uncertainty - our estimates will change if we re-run our experiment. We can quantify this level of uncertainty with a standard error - basically, how much will our results change if we re-ran the experiment.\n\nSmaller standard errors means we are more confident about our estimates: the results will not change much if we redo the experiment.\nLarger standard errors means we are less certain about our estimates: the results will change a lot if we redo the experiment.\n\nWhat if our uncertainty means that we might not have a causal effect, even though we found a causal effect with our experiment?\nWell, with our standard errors, we can calculate how likely that there is zero (no) causal effect (called a p-value). This procedure is called a hypothesis test. Our p-value for a causal effect estimate tells us:\n\n\n\n\n\n\n\n\nP-Value\nImplication\nConclusion\n\n\n\n\nLess than 0.05 (5%)\nThere is less than a 5% chance that there is a zero causal effect. This means a 95%+ chance that there is a causal effect.\nWe can conclude that the causal effect is statistically significant and conclude treatment causes the outcome.\n\n\nGreater than 0.05 (5%)\nThere is greater than a 5% chance that there is zero causal effect. This means a 95% or less chance that there is a causal effect.\nWe cannot conclude that there is a causal effect. The effect is not statistically significant.\n\n\n\n\n\n\n\nNote: a common question is why we determine significance at the threshold of 5%. The answer is tradition - there is no mathematical reason why we have to use 5%.",
    "crumbs": [
      "Basics of Causal Inference",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Magic of Randomisation</span>"
    ]
  },
  {
    "objectID": "rdd.html",
    "href": "rdd.html",
    "title": "Regression Discontinuity",
    "section": "",
    "text": "(Sharp) Regression Discontinuity is a popular design, used when treatment is assigned based on being above or below a cutoff.\n\n  Validity:  (4/5)\n\n\n  Interpretability:   (3/5)",
    "crumbs": [
      "Regression Discontinuity",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regression Discontinuity</span>"
    ]
  },
  {
    "objectID": "fuzzy.html",
    "href": "fuzzy.html",
    "title": "Fuzzy Discontinuity",
    "section": "",
    "text": "Fuzzy Regression Discontinuity is a design used when treatment is influenced, but not perfectly determined, by being above or below a cutoff.\n\n  Validity:  (3/5)\n\n\n  Interpretability:   (1/5)",
    "crumbs": [
      "Regression Discontinuity",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fuzzy Discontinuity</span>"
    ]
  },
  {
    "objectID": "did.html",
    "href": "did.html",
    "title": "Differences-in-Differences",
    "section": "",
    "text": "Differences-in-Differences is a popular design, used when all individuals are untreated in one year, and some individuals get treated the next year.\n\n  Validity:  (3/5)\n\n\n  Interpretability:   (4/5)",
    "crumbs": [
      "Differences-in-Differences",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Differences-in-Differences</span>"
    ]
  },
  {
    "objectID": "synthetic.html",
    "href": "synthetic.html",
    "title": "Synthetic Controls Method",
    "section": "",
    "text": "Synthetic Controls is a modern design, used when we have one or a few treated units, with data for many untreated units from many years before the treatment.\n\n  Validity:  (3/5)\n\n\n  Interpretability:   (4/5)",
    "crumbs": [
      "Differences-in-Differences",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Synthetic Controls Method</span>"
    ]
  },
  {
    "objectID": "matching.html",
    "href": "matching.html",
    "title": "How Matching Works",
    "section": "",
    "text": "Mia is in our study and receives the treatment. Mia’s individual causal effect is:\n\\[\n\\tau_{\\text{Mia}} = \\textcolor{purple}{Y^{(1)}_\\text{Mia}} - \\textcolor{red}{Y^{(0)}_\\text{Mia}}\n\\]\n\n\nThe counterfactual in red is unobserved.\nSince Mia receives the treatment in real life, we cannot observe the counterfactual where Mia does not get the treatment. However, we can estimate Mia’s counterfactual by finding someone else in our study, who did not receive the treatment, but is also really similar to Mia in all other ways.\nLet’s say Ava is really similar to Mia. Ava also happens to have not received the treatment. We can approximate Mia’s counterfactual using Ava’s observed outcome:\n\\[\n\\textcolor{red}{Y^{(0)}_\\text{Mia}} \\approx \\textcolor{purple}{Y^{(0)}_\\text{Ava}}\n\\]\nHaving approximated Mia’s counterfactual, we can now estimate Mia’s causal effect, as both quantities are observed:\n\\[\n\\begin{align}\n\\widehat\\tau_{\\text{Mia}} & = \\textcolor{purple}{Y^{(1)}_\\text{Mia}} - \\textcolor{purple}{Y^{(0)}_\\text{Ava}} \\\\\n& = Y_\\text{Mia} - Y_\\text{Ava}\n\\end{align}\n\\]\nWe can do the matching for every single person in the treatment group, then average all of these individual causal effects to get an estimate of the ATT.\n\\[\n\\widehat\\tau_\\text{ATT} = \\text{Average of all } \\widehat\\tau \\text{ of each pair}\n\\]\n\n\nMatching only estimates the ATT, not ATE.\nBy matching individuals with the same/very similar confounder values, we eliminate pre-existing differences, since our matched pairs will all be similar to each other. Thus, selection bias will not be a concern.\n\nFor matching to work, we must meet the following three assumptions:\n\n\n\n\n\n\n\n\n\n\n\nAssumption\nDescription\nHow to Check\n\n\n\n\nConditional Ignorability\nThis essentially means that when we match, we must account for all possible confounders.\nWe can conduct balance checks. This will be shown in the estimator pages.\n\n\nCommon Support\nThis means that no matter what an individual’s confounder values are, they always have at least a chance of being put into both treatment and control. Or in other words, no one can have a 100% chance of being in treatment or control.\nWe can check if our sample has at least one treated and one untreated per every confounder value. However, this isn’t a foolproof check, and its probably better to use theoretical reasoning.\n\n\nStable Unit Treatment Value Assumption (SUTVA)\nEach person’s treatment status only affects their own outcome, not anyone else. This means that if Ava is treated, that does not affect Mia’s outcome.\nWe have to use our own theoretical reasoning.\n\n\n\n\n\nTable 1: Ensure all of these assumptions are met if you are using matching\n\n\n\n\nThere are three estimators to implement matching. These are essentially different ways to calculate which units are “closest” to each other for matching.\n\n\n\n\n\n\n\n\nEstimator\nDescription\nWhen to Use\n\n\n\n\nDistance Matching\nMatches units by finding the units with the closest confounder values.\nWhen genetic matching is not possible, and we have less than 5 confounders and a small sample.\n\n\nPropensity Score Matching\nMatches units based on how close their likelihood of receiving treatment is.\nWhen genetic matching is not possible, and we have a large sample.\n\n\nGenetic Matching\nDistance matching, but with an additional weights/emphasis parameter putting more emphasis on some confounders than others.\nWhenever possible. Can require a good computer and take long for large data sets.\n\n\n\nUse the sidebar or links in the table to access each estimator’s page.",
    "crumbs": [
      "Matching Estimators",
      "How Matching Works"
    ]
  },
  {
    "objectID": "matching.html#what-is-matching",
    "href": "matching.html#what-is-matching",
    "title": "Overview of Matching",
    "section": "",
    "text": "See chapter 1 if this looks confusing to you.\n\n\n\n\nWhen we say “similar”, we mean with similar values for their confounding variables.\n\n\n\n\n\n\nThe hat on \\(\\hat\\tau\\) indicates that this is an estimate, not the actual effect.\n\n\n\n\nSee Table 1.4 for what the ATT is, and how it differs from other causal effects.",
    "crumbs": [
      "Matching Estimators",
      "Overview of Matching"
    ]
  },
  {
    "objectID": "matching.html#assumptions",
    "href": "matching.html#assumptions",
    "title": "Overview of Matching",
    "section": "",
    "text": "Assumption\nDescription\nHow to Check\n\n\n\n\nConditional Ignorability\nThis essentially means that when we match, we must account for all possible confounders.\nWe can conduct balance checks. This will be shown in the estimator pages.\n\n\nCommon Support\nThis means that no matter what an individual’s confounder values are, they always have at least a chance of being put into both treatment and control. Or in other words, no one can have a 100% chance of being in treatment or control.\nWe can check if our sample has at least one treated and one untreated per every confounder value. However, this isn’t a foolproof check, and its probably better to use theoretical reasoning.\n\n\nStable Unit Treatment Value Assumption (SUTVA)\nEach person’s treatment status only affects their own outcome, not anyone else. This means that if Ava is treated, that does not affect Mia’s outcome.\nWe have to use our own theoretical reasoning.\n\n\n\n\n\nTable 1: Ensure all of these assumptions are met if you are using matching",
    "crumbs": [
      "Matching Estimators",
      "Overview of Matching"
    ]
  },
  {
    "objectID": "matching.html#estimators",
    "href": "matching.html#estimators",
    "title": "Overview of Matching",
    "section": "",
    "text": "Estimator\nDescription\nWhen to Use\n\n\n\n\nDistance Matching\nMatches units by finding the units with the closest confounder values.\nWhen genetic matching is not possible, and we have less than 5 confounders and a small sample.\n\n\nPropensity Score Matching\nMatches units based on how close their likelihood of receiving treatment is.\nWhen genetic matching is not possible, and we have a large sample.\n\n\nGenetic Matching\nDistance matching, but with an additional weights/emphasis parameter putting more emphasis on some confounders than others.\nWhenever possible. Can require a good computer and take long for large data sets.",
    "crumbs": [
      "Matching Estimators",
      "Overview of Matching"
    ]
  },
  {
    "objectID": "distance.html",
    "href": "distance.html",
    "title": "Distance Matching",
    "section": "",
    "text": "Distance matching matches an individual that is treated (like Mia) with one that is not treated based on how close their confounding values are. We define closeness by Mahalanobis distance:\n\\[\n\\delta_{i, j} = \\sqrt{(\\b x_i - \\b x_j)^\\top \\b\\Sigma_x^{-1} (\\b x_i - \\b x_j)}\n\\]\n\n\nWhere \\(i\\) and \\(j\\) are two units we want to measure the distance between, \\(\\b x\\) are their confounder values, and \\(\\b\\Sigma_x\\) is the covariance matrix of confounders.\nIt is basically a way to measure distance across multiple dimensions, adjusting for the scale at which confounders are measured. The treated and untreated units that have the smallest distance between them are matched together.\nDistance matching is not the best method of matching - it tends to struggle with anything more than 5 confounders, because of the curse of dimensionality.\n\nThis basically means its hard to find close matches when you have more confounders.\nWhen you have more confoundners, you should instead use genetic matching (preferred) or propensity score matching.\n\n\nTo implement distance matching, we will need the Matching package.\n\nlibrary(Matching)\n\nNow, we can implement the matching as follows.\n\natt &lt;- Match(Y = my_data$Y,\n             Tr = my_data$D,\n             X = my_data[,c(\"X1\",\"X2\", \"X3\")],\n             M = 1,\n             BiasAdjust = TRUE,\n             Weight = 2)\nsummary(att)\n\n\n\nBiasAdjust is a complex method that reduces the bias in matching due to imperfect matches. You can change M (number of matches per treated unit) for better matches.\nOur output estimate will be the ATT.",
    "crumbs": [
      "Matching Estimators",
      "Distance Matching"
    ]
  },
  {
    "objectID": "distance.html#what-is-distance-matching",
    "href": "distance.html#what-is-distance-matching",
    "title": "Distance Matching",
    "section": "",
    "text": "Where \\(i\\) and \\(j\\) are two units we want to measure the distance between, \\(\\b x\\) are their confounder values, and \\(\\b\\Sigma_x\\) is the covariance matrix of confounders.",
    "crumbs": [
      "Matching Estimators",
      "Distance Matching"
    ]
  },
  {
    "objectID": "distance.html#implementing-distance-matching",
    "href": "distance.html#implementing-distance-matching",
    "title": "Distance Matching",
    "section": "",
    "text": "To install, do install.packages(‘package_name’)\n\n\n\n\n\nReplace Y with the outcome variable, D with the treatment variable, X1 X2 X3 with the confounders, and my_data with your data.\n\n\n\n\nFor those who received treatment D, treatment D on average caused a 1.6197 unit change in outcome Y.\n\n\n\n\nConsult Table 1 for the assumptions.\n\n\n\nThe p-value in this outcome is written in scientific notation. You can always copy into google to see what it equals.",
    "crumbs": [
      "Matching Estimators",
      "Distance Matching"
    ]
  },
  {
    "objectID": "pscore.html",
    "href": "pscore.html",
    "title": "Propensity Score Matching",
    "section": "",
    "text": "Propensity Score Matching matches an individual that is treated (like Mia) with one that is not treated based on how similar their likelihoods of treatment are.\nWhat is a likelihood of treatment? Well we know confounders cause people to get the treatment or not treatment. Thus, using an individual’s confounder values, we can estimate their likelihood of getting treatment, called a propensity score.\n\\[\n\\text{propensity score } \\pi =Pr(\\text{you get treated})\n\\]\nThe conventional way of estimating the propensity score (likelihood of getting treated) is to use a logistic regression model, with your treatment status as the dependent variable, and your confounder values as the independent variables.\nHowever, this means that propensity score matching is vulnerable to how good our logistic regression model used to estimate propensity scores are.\n\nThis is one of the reasons that genetic matching is now the preferred method for matching - and propensity score matching is used more as a backup.\n\n\n\nThere are also some criticisms of propensity score outlined here.\n\nTo implement propensity score matching, we will need the Matching package.\n\nlibrary(Matching)\n\nFirst, we need to estimate the propensity scores with a logistic regression:\n\npropensity &lt;- glm(D ~ X1 + X2,\n                  data = my_data,\n                  family = \"binomial\")\nmy_data$pscore &lt;- predict(propensity,\n                          type = \"response\")\n\n\n\nA random forest model is also possible, but less common.\nNow, we can implement the matching as follows.\n\natt &lt;- Match(Y = my_data$Y,\n             Tr = my_data$D,\n             X = my_data[,\"pscore\"],\n             M = 1,\n             BiasAdjust = TRUE,\n             Weight = 2)\nsummary(att)\n\n\n\nReplace Y with the outcome variable, D with the treatment variable.\nOur output estimate will be the ATT.",
    "crumbs": [
      "Matching Estimators",
      "Propensity Score Matching"
    ]
  },
  {
    "objectID": "pscore.html#what-is-propensity-score-matching",
    "href": "pscore.html#what-is-propensity-score-matching",
    "title": "Propensity Score Matching",
    "section": "",
    "text": "There are also some criticisms of propensity score outlined here.",
    "crumbs": [
      "Matching Estimators",
      "Propensity Score Matching"
    ]
  },
  {
    "objectID": "pscore.html#implementing-propensity-score-matching",
    "href": "pscore.html#implementing-propensity-score-matching",
    "title": "Propensity Score Matching",
    "section": "Implementing Propensity Score Matching",
    "text": "Implementing Propensity Score Matching\nTo implement propensity score matching, we will need the Matching package. If you never have installed the package, you should install them. Let us load the packages:\n\n\nTo install, do install.packages(‘package_name’)\n\nlibrary(Matching)\n\nFirst, we need to estimate the propensity scores with a logistic regression:\n\npropensity &lt;- glm(D ~ X1 + X2,\n                  data = my_data,\n                  family = \"binomial\")\nmy_data$pscore &lt;- predict(propensity,\n                          type = \"response\")\n\n\n\nReplace D with our treatment variable, and X1 and X2 with our confounders. Replace my_data with our study data.\nNow, we can implement the matching as follows.\n\natt &lt;- Match(Y = my_data$Y,\n             Tr = my_data$D,\n             X = my_data[,\"pscore\"],\n             M = 1,\n             BiasAdjust = TRUE,\n             Weight = 2)\nsummary(att)\n\n\n\nReplace Y with the outcome variable, D with the treatment variable.\nOur results will look something like this:\n\n\n\nEstimate...  1.6197 \nAI SE......  0.13059 \nT-stat.....  12.403 \np.val......  &lt; 2.22e-16 \n\nOriginal number of observations..............  1000 \nOriginal number of treated obs...............  254 \nMatched number of observations...............  254 \nMatched number of observations  (unweighted).  333 \n\n\nOur causal effect is given by the Estimate, which we can see is 1.6197. Distance matching estimates the ATT, so we interpret the estimate as:\n\nFor those who received treatment D, treatment D on average caused a 1.6197 unit change in outcome Y.\n\nThis causal effect is only accurate if we have met the assumptions of conditional ignorability, common support, and SUTVA.\n\n\nConsult Table 1 for the assumptions.\nIf we look at the p-value, we can see it is less than 0.05. Thus, we have a statistically significant causal effect.\n\n\nThe p-value in this outcome is written in scientific notation. You can always copy into google to see what it equals.\nThe output also tells us the original number of observations, and the matched number of observations. Since matching discards individuals who were not matched, this is a useful measure to see how much of our data we lost.",
    "crumbs": [
      "Matching Estimators",
      "Propensity Score Matching"
    ]
  },
  {
    "objectID": "genetic.html",
    "href": "genetic.html",
    "title": "Genetic Matching",
    "section": "",
    "text": "Genetic matching is an extension of distance matching. Like distance matching, genetic matching matches an individual that is treated (like Mia) with one that is not treated based on how close their confounding values are.\nHowever, unlike distance matching, which uses a standard mahalanobis distance, genetic matching uses a mahalanobis distance that puts different weights/emphasis on different confounders:\n\\[\n\\delta_{i, j}(\\b W) = \\sqrt{(\\b x_i - \\b x_j)^\\top (\\b\\Sigma_x^{-1/2})^\\top \\b W \\b\\Sigma_x^{-1/2}  (\\b x_i - \\b x_j)}\n\\]\n\n\nWhere \\(i\\) and \\(j\\) are two units we want to measure the distance between, \\(\\b x\\) are their confounder values, and \\(\\b\\Sigma_x\\) is the covariance matrix of confounders. \\(\\b W\\) is a weights matrix.\nIt is basically a way to measure distance across multiple different confounders, adjusting for the scale at which confounders are measured, and weighting some confounders more than others.\nThe weights \\(\\b W\\) are estimated to make the treated and untreated groups as similar as possible. Then, the treated and untreated units that have the smallest distance between them are matched together.\nGenetic matching has been shown by studies to perform better in causal estimation than distance or propensity score matching.\n\nHowever, genetic matching is also more computationally intensive, so for large data sets, propensity score matching might be quicker.\n\n\nTo implement propensity score matching, we will need the Matching and MatchIt package.\n\nlibrary(Matching)\n\nFirst, we need to estimate the propensity scores with a logistic regression. It is recommended to use the propensity score as one of the controls on which to genetic match on.\n\npropensity &lt;- glm(D ~ X1 + X2,\n                  data = my_data,\n                  family = \"binomial\")\nmy_data$pscore &lt;- predict(propensity,\n                          type = \"response\")\n\nThen, we use the GenMatch() function to estimate a weights matrix \\(\\b W\\):\n\nset.seed(333) #any number works\ngen &lt;- GenMatch(Tr = my_data$D,\n                    X = my_data[,c(\"X1\",\"X2\",\"pscore\")],\n                    BalanceMatrix = my_data[,c(\"X1\",\"X2\")],   \n                    estimand = \"ATT\",\n                    M = 2,\n                    replace = TRUE,\n                    ties = FALSE,\n                    distance.tolerance = 0,\n                    print.level = 0,\n                    pop.size = 200)\n\n\n\nYou can increase pop.size to increase the accuracy - but it will increase the time and computational power needed.\nNow, let us conduct estimation with genetic matching:\n\natt &lt;- Match(Y = my_data$Y,\n             Tr = my_data$D,\n             X = my_data[,c(\"X1\",\"X2\",\"pscore\")],\n             estimand = \"ATT\",\n             M = 2,\n             replace = TRUE,\n             ties = FALSE,\n             distance.tolerance = 0,\n             Weight.matrix = gen$Weight.matrix,\n             Weight = 3)\n\nOur output will be the ATT.",
    "crumbs": [
      "Matching Estimators",
      "Genetic Matching"
    ]
  },
  {
    "objectID": "genetic.html#what-is-genetic-matching",
    "href": "genetic.html#what-is-genetic-matching",
    "title": "Genetic Matching",
    "section": "",
    "text": "Where \\(i\\) and \\(j\\) are two units we want to measure the distance between, \\(\\b x\\) are their confounder values, and \\(\\b\\Sigma_x\\) is the covariance matrix of confounders. \\(\\b W\\) is a weights matrix.",
    "crumbs": [
      "Matching Estimators",
      "Genetic Matching"
    ]
  },
  {
    "objectID": "genetic.html#implementing-genetic-matching",
    "href": "genetic.html#implementing-genetic-matching",
    "title": "Genetic Matching",
    "section": "",
    "text": "To install, do install.packages(‘package_name’)\n\n\n\n\n\nReplace D with our treatment variable, and X1 and X2 with our confounders. Replace my_data with our study data.\n\n\n\n\nReplace D with our treatment variable, and X1 and X2 with our confounders. Replace my_data with our study data.\n\n\n\n\nReplace Y with the outcome variable, D with the treatment variable.\n\n\n\n\nFor those who received treatment D, treatment D on average caused a 1.6197 unit change in outcome Y.\n\n\n\n\nConsult Table 1 for the assumptions.\n\n\n\nThe p-value in this outcome is written in scientific notation. You can always copy into google to see what it equals.",
    "crumbs": [
      "Matching Estimators",
      "Genetic Matching"
    ]
  },
  {
    "objectID": "weighting.html",
    "href": "weighting.html",
    "title": "Weighting Estimator",
    "section": "",
    "text": "What is Inverse Probability Weighting?\nLet us look back at an earlier example from chapter 2:\nWe know we are concerned about confounders. Smoking is a potential confounder.\nLet’s pretend our smoking confounder has 2 categories: people who do not smoke, and frequent smokers. Let’s focus on the frequent smokers. We might have 5 frequent smokers in our study: Ava, Ben, Mia, Max, and Zoe. Because smoking makes you more likely to need to go to the hospital, their treatment statuses look like:\nThis is a clear selection bias issue - smoking is affecting who gets treated, and smoking also results in worse health outcomes. Inverse probability weighting is a solution to solve selection bias. It essentially emphaises certain individuals to “solve” selection bias.\nFor example, inverse probability weighting would “pretend” that the frequent smokers table from above actually looks like:\nBy emphasising Ben and making him worth 4 individuals (and doing something similar in the non-smoking category), inverse probability weighting has essentially solved the selection bias issue by making it so that confounders do not affect the likelihood of getting treatment.\nSince confounders influence the likelihood of an individual getting treatment, we can estimate that likelihood of getting treatment, given an individual’s confounder levels. Inverse probability weighting decides the weight/emphasis of every individual based on the inverse of their likelihood to receive treatment.",
    "crumbs": [
      "Weighting Estimators",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Weighting Estimator</span>"
    ]
  },
  {
    "objectID": "weighting.html#what-is-inverse-probability-weighting",
    "href": "weighting.html#what-is-inverse-probability-weighting",
    "title": "Weighting Estimator",
    "section": "",
    "text": "example1\n\n\n\nD\n\nGoing to the Hospital\n\n\n\nY\n\nHealth Outcomes\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexample2\n\n\n\nD\n\nGoing to the Hospital\n\n\n\nY\n\nHealth Outcomes\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\nX\n\nSmoking (Confounder)\n\n\n\nX-&gt;D\n\n\n\n\n\nX-&gt;Y\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote: smoking is not the only possible confounder, we just use it as an example. Drinking, age, etc. are all other potential confounders. To find the causal effect, you must account for all confounders.\n\n\n\n\n\n\n\n\nTreated (Hospital)\nUntreated\n\n\n\n\nAva, Mia, Max, Zoe\nBen\n\n\n\n\n\nThe opposite is true for non-smokers: 4 of the 5 are in the untreated group, and only 1 of 5 are in the treated.\n\n\n\n\n\n\n\n\n\nTreated (Hospital)\nUntreated\n\n\n\n\nAva, Mia, Max, Zoe\nBen, Ben, Ben, Ben\n\n\n\n\n\n\n\nThe inverse of the likelihood of getting treatment means that individuals less likely to receive treatment will be weighted more, as shown with Ben above.",
    "crumbs": [
      "Weighting Estimators",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Weighting Estimator</span>"
    ]
  },
  {
    "objectID": "weighting.html#when-should-you-use-this-method",
    "href": "weighting.html#when-should-you-use-this-method",
    "title": "Weighting Estimator",
    "section": "When Should You Use this Method?",
    "text": "When Should You Use this Method?\nWhen can/should you use weighting?\n\nIf none of random experiments, regression discontinuity (including fuzzy), differences-in-differences, or instrumental variables are possible.\nIf you have a large sample size (generally over 200 observations for both treated and untreated). If you have a smaller sample size, consider distance matching.\nYou are interested in the ATE instead of the ATT. If you want the ATT, consider matching.\nYou know and have data on all the confounders in question.\n\nThen, check you have met these assumptions:\n\nConditional Ignorability: we must know all confounders, and have data on all confounders, and include all confounders in our estimation.\nWe must have a sufficiently large sample size, as weighting is inaccurate in smaller sample sizes. We should have at least 200 observations per treatment group (treated and untreated). The more confounders you have, the larger sample you need.\n\n\nMy RatingsAdvantagesDisadvantages\n\n\n\n  Validity:   (2/5)\n\nHow convincing is this method at accurately estimating the true causal effects?\n\nIt is often difficult to justify that you have accounted for all possible confounders. The estimator is also biased in small samples, but big-data is pretty available these days.\nThis makes the design less convincing than all other methods, except matching which is about the same level of convincing.\nIt is often used when we cannot use other better methods.\n\n\n  Interpretability:   (5/5)\n\nHow useful are the results from this method?\n\nThe estimand is the ATE, probably the most generalisable effect summary.\n\n\n\nIf none of random experiments, instrumental variables, regression discontinuity, or differences-in-differences are possible, you generally resort to matching or weighting.\nWeighting does have some advantages over matching in some situations.\n\nWeighting uncovers the ATE, while matching can only uncover the ATT. Often, we are interested in the ATE, since the ATT is only the causal effects for people who received the treatment, when we are interested in what will happen when we expand a treatment to others.\nWeighting performs better with larger numbers of covariates, especially compared with distance matching.\n\n\n\nWeighting has disadvantages when compared to other methods.\n\nInverse probability weighting requires you to include every single confounder. This is often not possible. Sometimes, we just do not know enough about a topic to know all the confounders, or we know a confounder, but it is impossible to measure. Methods like random experiments, instrumental variables, regression discontinuity, or differences-in-differences can find causal effects without knowing all confounders.\nInverse probability weighting can be very inaccurate with small samples. This is because the estimator becomes very sensitive to extreme propensity score values, which occurs more often in small samples. In small samples, distance matching is more accurate.",
    "crumbs": [
      "Weighting Estimators",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Weighting Estimator</span>"
    ]
  },
  {
    "objectID": "weighting.html#implementing-inverse-probability-weighting",
    "href": "weighting.html#implementing-inverse-probability-weighting",
    "title": "Weighting Estimator",
    "section": "Implementing Inverse Probability Weighting",
    "text": "Implementing Inverse Probability Weighting\nTo implement inverse probability weighting, we need to first estimate our propensity scores (likelihood of an individual being treated based on their confounders). The propensity scores will be needed as part of the calculation of weights/emphasis for each individual.\n\n\n\n\n\n\nWe must use all confounders in our prediction of propensity scores. If we leave out any possible confounder, our predicted likelihood of treatment values will be wrong, and our causal estimates will be wrong.\n\n\n\nBefore we start, we will need the MatchIt and estimatr packages. If you never have installed the packages, you should install them. Let us load the packages:\n\nlibrary(MatchIt)\nlibrary(estimatr)\n\nTo estimate the propensity score, we can use the glm() command:\n\npropensity &lt;- glm(D ~ X1 + X2, data = my_data, family = \"binomial\")\nmy_data$pscore &lt;- predict(propensity, type = \"response\")\n\n\n\nReplace D with our treatment variable, and X1 and X2 with our confounders. Replace my_data with our study data.\nThen, we need to create our weights, which are the inverse of the propensity scores:\n\nmy_data$ipw &lt;- ifelse(mydata$D == 1, 1/my_data$pscore, 1/(1-my_data$pscore))\n\n\n\nReplace D with our treatment variable, and my_data with our study data.\nFinally, we need to use the lm_robust() command to estimate our causal effects:\n\nate &lt;- estimatr::lm_robust(Y ~ D, data = my_data, weights = ipw)\nsummary(ate)\n\n\n\nReplace Y with the outcome variable, D with the treatment, and my_data with our study data.\nThis will output the results, which I will show how we interpret in the next section.",
    "crumbs": [
      "Weighting Estimators",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Weighting Estimator</span>"
    ]
  },
  {
    "objectID": "weighting.html#interpreting-the-results",
    "href": "weighting.html#interpreting-the-results",
    "title": "Weighting Estimator",
    "section": "Interpreting the Results",
    "text": "Interpreting the Results\nOur results will look something like this:\n\n\n\nCall:\nestimatr::lm_robust(formula = Y ~ D, data = data, weights = ipweight)\n\nWeighted, Standard error type:  HC2 \n\nCoefficients:\n            Estimate Std. Error t value   Pr(&gt;|t|) CI Lower CI Upper  DF\n(Intercept)     1.29    0.03688   34.97 1.458e-175    1.218    1.362 998\nD               1.78    0.15237   11.68  1.219e-29    1.481    2.079 998\n\nMultiple R-squared:  0.3066 ,   Adjusted R-squared:  0.3059 \nF-statistic: 136.5 on 1 and 998 DF,  p-value: &lt; 2.2e-16\n\n\nOur causal estimate is given in the coefficients table, in the D (treatment) row and Estimate column. We can see the causal effect is estimated to be 1.78. Propensity score matching estimates the ATE (see table Table 1.4), so we interpret the estimate as:\n\nTreatment D on average caused a 1.4733 unit change in outcome Y.\n\n\n\n\n\n\n\nOur causal estimates are only accurate if we used all confounders in our propensity score estimation. If we forgot even just one confounder, our estimates will be wrong.\n\n\n\nIf we look at the p-value (labelled Pr(&gt;|t|)), we can see it is less than 0.05. Thus, we have a statistically significant causal effect.\n\n\nThe p-value in this outcome is written in scientific notation. You can always copy into google to see what it equals.",
    "crumbs": [
      "Weighting Estimators",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Weighting Estimator</span>"
    ]
  },
  {
    "objectID": "frameworks.html#potential-outcomes",
    "href": "frameworks.html#potential-outcomes",
    "title": "Basics of Causation",
    "section": "",
    "text": "Parallel World\nPotential Outcome\n\n\n\n\nDoes not Receive Treatment: \\(D = 0\\)\n\\(\\C\\)\n\n\nReceives Treatment: \\(D = 1\\)\n\\(\\T\\)\n\n\n\n\n\nTable 1.1: The (0) and (1) are not exponents - they label the outcome \\(Y\\) for treatment status.\n\n\n\n\n\n\n\nNote: For this to be the causal effect, we need an additional assumption, SUTVA. See appendix B.",
    "crumbs": [
      "Basics of Causal Inference",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of Causation</span>"
    ]
  },
  {
    "objectID": "frameworks.html#why-correlation-is-not-causation-selection-bias",
    "href": "frameworks.html#why-correlation-is-not-causation-selection-bias",
    "title": "Basics of Causation",
    "section": "",
    "text": "example1\n\n\n\nD\n\nGoing to the Hospital (D)\n\n\n\nY\n\nHealth Outcomes (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\n\n\n\n\n\n\n\n\nThe average health of individuals who got hospital treatment is low.\nThe average health of individuals who did not get hospital treatment is high.\nThus, we find that hospital treatment is correlated with worse health outcomes.\n\n\n\nLess healthy people are more likely to go to the hospital to get treated in the first place. That means before the hospital even begins treatment, there are pre-existing differences between people getting treatment and people that are untreated.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTreated\nUntreated\n\n\n\n\nObserved \\(\\mean Y\\)\n\\(\\mean Y_\\text{treated} = \\textcolor{purple}{\\mean Y_{\\text{treated}}^{(1)}}\\)\n\\(\\mean Y_\\text{untreated} = \\textcolor{purple}{\\mean Y_{\\text{untreated}}^{(0)}}\\)\n\n\nCounterfactual\n\\(\\textcolor{red}{\\mean Y_{\\text{treated}}^{(0)}}\\)\n\\(\\textcolor{red}{\\mean Y_{\\text{untreated}}^{(1)}}\\)\n\n\nReal Treatment Effect\n\\(\\textcolor{purple}{\\mean Y_{\\text{treated}}^{(1)}} - \\textcolor{red}{\\mean Y_{\\text{treated}}^{(0)}}\\)\n\\(\\textcolor{red}{\\mean Y_{\\text{untreated}}^{(1)}} - \\textcolor{purple}{\\mean Y_{\\text{untreated}}^{(0)}}\\)\n\n\n\n\n\nTable 1.4: This table uses what we learned about counterfactuals (Table 1.2) and treatment effects.\n\n\n\n\n\n\n\n\nWhat are these two values? They are the average potential outcomes of each group (treatment and control), in the parallel world of not recieving the treatment.\nOr we can think of it as the average outcomes before treatment.\n\n\n\n\nThe confounder is correlated (positive or negative) with the outcome variable.\nThe confounder causes who gets and doesn’t get the treatment.\nThe confounder is not itself caused by the treatment.\n\n\n\n\n\n\nSmoking will worsen health outcomes. Someone who smokes is also more likely to visit the hospital with health complications.\nThat means people who go to the hospital start out with (on average) worse health outcomes than people who did not go to the hospital.\n\n\n\nNote: smoking is not the only possible confounder, we just use it as an example. Drinking, age, etc. are all other potential confounders.\n\n\n\n\n\n\n\n\nexample2\n\n\n\nD\n\nGoing to the Hospital (D)\n\n\n\nY\n\nHealth Outcomes (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\nX\n\nSmoking (Confounder)\n\n\n\nX-&gt;D\n\n\n\n\n\nX-&gt;Y",
    "crumbs": [
      "Basics of Causal Inference",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of Causation</span>"
    ]
  },
  {
    "objectID": "frameworks.html#confounders-and-the-cause-of-selection-bias",
    "href": "frameworks.html#confounders-and-the-cause-of-selection-bias",
    "title": "Basics of Causation",
    "section": "Confounders and the Cause of Selection Bias",
    "text": "Confounders and the Cause of Selection Bias\nA confounder is a third variable that has the following characteristics:\n\nThe confounder is correlated (positive or negative) with the outcome variable.\nThe confounder causes who gets and doesn’t get the treatment.\nThe confounder is not itself caused by the treatment.\n\nA confounder will cause some people to get the treatment, and others to not get the treatment. A confounder is also correlated with the outcome.\nThese two facts mean that before we even start the treatment, people who will get the treatment differ from people who will not get the treatment.\nThus, confounders cause selection bias and pre-existing differences.\nFor example, in our hospital-health example, a confounder could be smoking.\n\nSmoking will worsen health outcomes. Someone who smokes is also more likely to visit the hospital with health complications.\nThat means people who go to the hospital start out with (on average) worse health outcomes than people who did not go to the hospital.\n\n\n\nNote: smoking is not the only possible confounder, we just use it as an example. Drinking, age, etc. are all other potential confounders.\n\n\n\n\n\n\n\n\nexample2\n\n\n\nD\n\nGoing to the Hospital (D)\n\n\n\nY\n\nHealth Outcomes (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\nX\n\nSmoking (Confounder)\n\n\n\nX-&gt;D\n\n\n\n\n\nX-&gt;Y\n\n\n\n\n\n\n\n\n\n\n\n\nThis means that the treated group has more smokers and people with bad health than the untreated group. This pre-existing difference between treated and untreated means correlation is not equal to causation.\nSo we now know that correlation is not equal to causation, because confounders cause selection bias. Thus, if we have a correlation, and we want to find the causal effect, we have to eliminate the influence of confounders, which will eliminate the reason correlation does not equal causation.\nThus, researchers need to employ research designs that can eliminate the errors caused by confounders, and identify the causal effect. The rest of this book explores these research designs.",
    "crumbs": [
      "Basics of Causal Inference",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of Causation</span>"
    ]
  }
]