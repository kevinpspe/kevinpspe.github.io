[
  {
    "objectID": "factor.html",
    "href": "factor.html",
    "title": "Factor Analysis Model",
    "section": "",
    "text": "See here for an overview of latent variable models, and the other models available.\n\n\n\n\n\n\n\n\n\nexample2\n\n\n\nF\n\nLatent Factor (F)\n\n\n\nX1\n\nItem 1 (X1)\n\n\n\nF-&gt;X1\n\n\nλ\n\n\n\nX2\n\nItem 2 (X2)\n\n\n\nF-&gt;X2\n\n\nλ\n\n\n\nX3\n\nItem 3 (X3)\n\n\n\nF-&gt;X3\n\n\nλ\n\n\n\n\n\n\n\n\n\nFactor analysis assumes that the unobserved latent factor is continuous and distributed \\(F \\sim \\mathcal N(0, 1)\\). We assume the items \\(X_1, X_2, \\dots\\) are normally distributed.\n\nTechnically, we don’t need \\(F\\) to be strictly a standard normal. See appendix D.\n\nWe assume each observed item \\(X_1, X_2, \\dots\\) is related to the factor with a linear model:\n\\[\n\\begin{align}\nX_1 & = \\tau_1 + \\lambda_1F + \\delta_1 &  \\delta_1 \\sim \\mathcal N(0, \\theta_{11})\\\\\nX_2 & = \\tau_2 + \\lambda_2 F + \\delta_2 &  \\delta_2 \\sim \\mathcal N(0, \\theta_{22})\n\\end{align}\n\\]\n\nFactor loadings \\(\\lambda_1, \\lambda_2, \\dots\\) are the covariance between \\(X_1, X_2, \\dots\\) and the factor \\(F\\). If \\(X_1, X_2, \\dots\\) are standardised to a standard normal, then \\(\\lambda_1, \\lambda_2, \\dots\\) are also the correlation coefficient.\n\nFactor analysis also works with multiple factors \\(F_1, F_2, \\dots\\). Each item \\(X_1, X_2, \\dots\\) could measure all factors, or only some. Factors can also be correlated with each other. For multiple factors, the measurement model now relates each item to all factors:\n\\[\n\\begin{align}\nX_1 & = \\tau_1 + \\lambda_{11}F_1 + \\lambda_{12}F_2 + \\dots + \\delta_1 &  \\delta_1 \\sim \\mathcal N(0, \\theta_{11})\\\\\nX_2 & = \\tau_2 + \\lambda_{21} F_1 + \\lambda_{22}F_2 + \\dots +\\delta_2 &  \\delta_2 \\sim \\mathcal N(0, \\theta_{22})\n\\end{align}\n\\]\n\nThe model not only estimates each \\(\\lambda\\), but also the covariance between factors. When dealing with multiple factors, there are actually many different possible results, that involve rotation (see appendix A).\n\nInterpretation of a factor \\(F\\), is based on the factor loadings \\(\\lambda\\). A larger (absolute value) factor loading from one item indicates stronger “measurement” influence of a item by that factor. A closer to 0 loading means the factor does not measure that item. The sign of the factor describes the direction of the relationship.\n\nsee appendix B for an example of interpretation.\n\nWe can also create factor scores for each individual in our model. These are linear combinations of the items with weights.\n\\[\n\\widetilde F = w_0 + w_1 X_1 + w_2X_2 + \\dots\n\\]\n\nThe weights \\(w_1, w_2, \\dots\\) are for each item \\(X_1, X_2, \\dots\\) when creating the factor scores (see appendix C).\n\nTo implement factor analysis, we will need the psych and GPArotation package:\n\nlibrary(psych)\nlibrary(GPArotation)\n\nFirst, we should get rid of missing observations:\n\nall.obs &lt;- apply(my_data, 1, FUN=function(x){all(!is.na(x))})\ndta &lt;- my_data[all.obs,]\n\nFor factor analysis with one factor, we use the syntax:\n\nfa &lt;- fa(data[,items], nfactors=1, fm=\"ml\")\nprint(fa1)\n\n\nsee appendix B for an interpretation example.\n\nFor factor analysis with multiple factors, we use the syntax:\n\nfa &lt;- fa(data[,items], nfactors=2, fm=\"ml\", rotate=\"oblimin\")\nprint(fa)\n\n\nThis is the code for an oblique rotation. For an orthogonal rotation (don’t use unless your goal is dimensional reduction), change “oblimin” to “none”.\n\nTo access factor scores, use the code:\n\nfa$scores\n\nWe can use these factor scores in other statistical models.\n\n\nAppendix\n\n\n\n\n\n\nAppendix A: Details on Factor Rotation\n\n\n\n\n\n\nThere are two types of rotation of factors.\nOrthogonal rotations basically assume that there is no correlation between the factors (they are perpendicular in vector space). This is good for dimensional reduction.\nOblique rotations allow for correlation between factors. This is good for interpretation, as they get some loadings close to 0, allowing for easier interpretation of a factor.\nBelow is a figure showing the difference between the two with 2 factors.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAppendix B: Interpretation Example\n\n\n\n\n\n\nThis is a typical output of factor anlaysis. ML1 and ML2 are the two factors, and the rows are items (which are trust in different institutions).\n\n\n\nFor factor 1 (ML1), we can see that pol_parties, politicians have very large loadings. EP, parliament, and UN have moderate loadings. Police and legal have almost 0 loadings. Almost all loadings are positive.\nThis tells us that factor 1 is a latent variable that measures mostly trust in politicians, rather than the legal/policing system. Since the loadings are almost all positive, we can conclude that higher values of factor 1 mean higher levels of trust in legal/policing systems.\nFor factor 2, we see that legal and police have the highest loadings, UN and parliament next, and the rest having very low loadings. These are positive loadings mostly.\nWe might interpret this as higher values of factor 2 mean higher trust in institutions, rather than political actors, since the high loadings are with mostly institutions, while politicians and pol_parties are very close to 0.\n\n\n\n\n\n\n\n\n\n\nAppendix C: Weights, Communality, and Reliability\n\n\n\n\n\n\nBefore we discuss the weights, let us define some concepts about the factor scores.\nRecall that for each item, \\(\\lambda\\) is a loading, and \\(\\theta\\) is the variance of the error term in the model.\n\n\\(\\lambda^2\\) is known as the communality - the variance in the item explained by the factor.\n\\(\\theta\\) is known as the residual variance or specific variance.\nThe proportion \\(\\lambda^2 / (\\lambda^2 + \\theta)\\) is the reliability of the item.\n\nIn factor scores, the items with the highest weights have the highest communalities.\n\n\n\n\n\n\n\n\n\n\nAppendix D: Factor Distribution Assumption\n\n\n\n\n\n\nThe factors \\(F\\) are required to be normally distributed:\n\\[\nF \\sim \\mathcal N(\\kappa, \\phi)\n\\]\nWhere \\(\\kappa\\) is the mean, and \\(\\phi\\) is the variance.\nHowever, this specification means there is actually no unique solution to \\(\\lambda\\) estimates. This is an identification issue. Thus, we have to make further assumptions.\nThe most common assumption is to make the factor a standard normal \\(F \\sim \\mathcal N(0, 1)\\), as we introduced above.\nHowever, instead of fixing the scale of the factor, we could also keep the factor flexible (allowing the model to estimate \\(\\kappa\\) and \\(\\phi\\)), and fix one item \\(X_1\\)’s model as:\n\\[\nX_1 = 0 + 1F + \\delta_1\n\\]\nWhere the intercept \\(\\tau_1\\) is fixed at 0, and the \\(\\lambda_1\\) is fixed at 1. This is less common.",
    "crumbs": [
      "Latent Variable Models",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Factor Analysis Model</span>"
    ]
  },
  {
    "objectID": "correlation.html",
    "href": "correlation.html",
    "title": "Issue of Selection Bias",
    "section": "",
    "text": "This page covers how confounders cause pre-existing differences between treated and untreated (selection bias), meaning correlation is not causation.\n\nLet us look at this causal question:\n\n\n\n\n\n\n\n\nexample1\n\n\n\nD\n\nGoing to the Hospital (D)\n\n\n\nY\n\nHealth Outcomes (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\n\n\n\n\n\n\nWe have a treated group (went to hospital), and an untreated group. Using our potential outcomes framework, we can define the treatment effect of the treated group:\n\\[\n\\tau_\\text{treated} = \\textcolor{purple}{\\mean Y_{\\text{treated}}^{(1)}} - \\textcolor{red}{\\mean Y_{\\text{treated}}^{(0)}}\n\\]\n\nIn red is the counterfactual we do not observe.\n\nNow compare the treatment effects above to correlation, which is defined as the difference in observed outcomes:\n\\[\n\\begin{align}\n\\text{correlation} & = \\mean Y_\\text{treated} - \\mean Y_\\text{untreated} \\\\\n& = \\textcolor{purple}{\\mean Y_{\\text{treated}}^{(1)}} - \\textcolor{purple}{\\mean Y_\\text{untreated}^{(0)}}\n\\end{align}\n\\]\nIf we compare this correlation to our \\(\\tau_\\text{treated}\\), we see:\n\\[\n\\text{if  } \\textcolor{purple}{\\mean Y_\\text{untreated}^{(0)}} ≠ \\textcolor{red}{\\mean Y_\\text{treated}^{(0)}}, \\text{ then }  \\tau_\\text{treated} ≠ \\text{correlation}\n\\]\n\nThese two quantities are potential outcomes under control, or in another way to think of it, outcomes of the two groups prior to treatment happening.\n\nThus, if there is a difference between the average outcomes between treated and untreated before treatment is administered, then correlation is not equal to causation. This is because we cannot tell if the difference between the groups is due to treatment, or due to their pre-existing differences.\n\nWhat causes pre-existing differences? Confounders. For example, in our hospital-health example, a confounder could be smoking.\n\nSmoking is not the only possible confounder, we just use it as an example. Drinking, age, etc. are all other potential confounders.\n\nSmoking will worsen health outcomes. Someone who smokes is also more likely to visit the hospital with health complications. That means people who go to the hospital start out with (on average) worse health outcomes than people who did not go to the hospital.\n\n\n\n\n\n\n\n\nexample2\n\n\n\nD\n\nGoing to the Hospital (D)\n\n\n\nY\n\nHealth Outcomes (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\nX\n\nSmoking (Confounder)\n\n\n\nX-&gt;D\n\n\n\n\n\nX-&gt;Y\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA confounder is a third variable that has the following characteristics:\n\nThe confounder is correlated (positive or negative) with the outcome variable.\nThe confounder causes who gets and doesn’t get the treatment.\nThe confounder is not itself caused by the treatment\n\n\n\n\n\nNote requirement 3 - it is a common mistake. Any result of the treatment \\(D\\) cannot be a confounder.\n\nConfounders cause pre-existing differences, which cause correlation to not equal causation. We must account for confounders to uncover causal effects.",
    "crumbs": [
      "Causal Inference Basics",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue of Selection Bias</span>"
    ]
  },
  {
    "objectID": "randomisation.html",
    "href": "randomisation.html",
    "title": "The Magic of Randomisation",
    "section": "",
    "text": "This chapter covers how randomisation solves the problem of selection bias, and why randomisation is considered the “gold standard” of causal inference.\n\nLet us say we are interested in this question:\n\n\n\n\n\n\n\n\nexample1\n\n\n\nD\n\nScholarship (D)\n\n\n\nY\n\nUniversity Performance (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\n\n\n\n\n\n\nOur concern is a confounder. For example, smartness of an individual could mean they are more likely to get a scholarship. Since smart people tend to perform well at university, that means the people who get treated are different from those who don’t get treated.\n\n\n\n\n\n\n\n\nexample2\n\n\n\nD\n\nScholarship (D)\n\n\n\nY\n\nUniversity Performance (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\nX\n\nSmartness (Confounder)\n\n\n\nX-&gt;D\n\n\n\n\n\nX-&gt;Y\n\n\n\n\n\n\n\n\n\n\n\n\n\nSmartness is not the only confounder. Other confounders could be family income, athletic ability, etc.\n\nBut what if randomness (like flipping a coin) controls who gets the treatment or not. A coin will be flipped to decide if every person in our study will get the scholarship. This means that the randomness (the coin), and not the confounder, are causing selection into treatment:\n\n\n\n\n\n\n\n\nexample2\n\n\n\nD\n\nScholarship (D)\n\n\n\nY\n\nUniversity Performance (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\nX\n\nSmartness (Confounder)\n\n\n\nX-&gt;Y\n\n\n\n\n\n\nO\n\nCoin\n\n\n\nO-&gt;D\n\n\n\n\n\n\n\n\n\n\n\nSince the confounder is no longer causing who gets the treatment and who doesn’t, that means there is no more concern of selection bias.\n\nRandomisation also means that every individual has the same chance of being treated or untreated, so the two groups will, on average, the same as each other. That means:\n\\[\n\\textcolor{purple}{\\mean Y_\\text{untreated}^{(0)}} = \\textcolor{red}{\\mean Y_\\text{treated}^{(0)}}, \\text{ so correlation} = \\text{causation}\n\\]\n\nThis is established by the law of large numbers, but it is a little technical for here.\n\nSo if our treatment is randomly assigned (individuals randomly assigned to treatment or control), correlation does equal causation.\n\nRandomisation is the gold standard of causal inference. There is no better method.\n\nRandomisation is possible if you are running your own experiment: you can use a random number generator to assign treatment.\nRandomisation is also possible if there is something that is being randomly assigned in the real world. For example, the US green card lottery randomly chooses who gets accepted.\n\nHowever, randomisation is not always possible to due to cost of running experiments, non-compliance of individuals within experiments, and impracticality.\n\nNon-compliance is an issue that can be solved pretty easily with an instrumental variable, given a few assumptions about the non-compliance.",
    "crumbs": [
      "Causal Inference Basics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Magic of Randomisation</span>"
    ]
  },
  {
    "objectID": "did.html",
    "href": "did.html",
    "title": "Difference-in-Differences",
    "section": "",
    "text": "Coming soon",
    "crumbs": [
      "Difference-in-Differences"
    ]
  },
  {
    "objectID": "fuzzy.html",
    "href": "fuzzy.html",
    "title": "Fuzzy Discontinuity",
    "section": "",
    "text": "Fuzzy Regression Discontinuity is a design used when treatment is influenced, but not perfectly determined, by being above or below a cutoff.\n\n  Validity:  (3/5)\n\n\n  Interpretability:   (1/5)",
    "crumbs": [
      "Regression Discontinuity",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Fuzzy Discontinuity</span>"
    ]
  },
  {
    "objectID": "regress.html",
    "href": "regress.html",
    "title": "Fully Interacted Estimator",
    "section": "",
    "text": "See here on how selection on observables works, and the other estimators available.\n\nRegression is a natural way to control for confounders in selection on observables:\n\\[\nY_i = \\alpha + D_i\\tau + \\b X_i' \\b\\beta + \\eps_i\n\\]\n\nWhere \\(\\alpha\\) is the intercept and \\(\\b X_i\\) is a vector of confounder values for individual \\(i\\).\n\nThe ordinary least squares (OLS) estimate \\(\\hat\\tau\\) will be an good estimator of the ATE if we account for all confounders (conditional ignorability) in vector \\(\\b X_i\\), and there is no treatment heterogeneity.\n\nHeterogeneity means not all individuals have the same treatment effect. More details on OLS estimation and unbiasedness given in appendix A and B. Why OLS is not equal to the ATE is given in appendix C.\n\nHeterogeneity is present in almost all situations we will need causal inference. Lin (2013) proposes the fully interacted estimator, which allows for consistent estimation of the ATE even with heterogeneity:\n\\[\nY_i = \\alpha + D_i \\tau + (\\b{X}_i - \\mean{\\b X})' \\b\\beta \\ + D_i (\\b X_i - \\mean{\\b X})' \\b\\gamma \\  + \\eps_i\n\\]\n\n\\(\\mean{\\b X}\\) is a vector of the means of each confounder. \\(\\tau\\) is the estimate of the ATE. See Lin (2013) for proofs.\n\n\n\n\n\n\n\n\nKevin’s Estimator Score:  (3/5)\n\nFully interacted estimator is decent at estimating the ATE, especially in large samples. We should be more careful in smaller samples.\nBig concern: the fully interacted estimator still assumes a linear relationship between confounders and the outcome. The other estimators covered later are non-parametric (not model based), so if we have any reason to suspect non-linearity, we should not use this estimator.\n\n\n\n\n\nBefore you implement the estimator, make sure you have reasons to believe you meet the neccessary assumptions for selection on observables.\nWe will need the estimatr package:\n\nlibrary(estimatr)\n\nThen, we can use the lm_lin() function to estimate:\n\nate &lt;- estimatr::lm_lin(Y ~ D,\n                        covariates = ~ X1 + X2 + X3,\n                        data = my_data)\nsummary(ate)\n\nThe output will be the ATE - the average treatment effect for all units in the study.\n\n\nAppendix\n\n\n\n\n\n\nAppendix A: OLS Estimator\n\n\n\n\n\n\nThe linear model can be written in matrix notation as:\n\\[\n\\b y = \\b{X\\beta} + \\b\\eps\n\\]\nWhere the treatment variable and confounders are included in matrix \\(\\b X\\).\nThe ordinary least squares estimator minimises the sum of squared residuals (SSR):\n\\[\nSSR = (\\b y - \\hat{\\b y})'(\\b y - \\hat{\\b y})\n\\]\nWe can re-arrange the SSR as follows:\n\\[\n\\begin{align}\nSSR & = (\\b y - \\hat{\\b y})'(\\b y - \\hat{\\b y}) \\\\\n& = (\\b y - \\b X \\hat{\\b\\beta})'(\\b y - \\b X \\hat{\\b\\beta})' \\\\\n& = \\b y' \\b y - 2 \\hat{\\b\\beta}' \\b X' \\b y + \\hat{\\b\\beta}' \\b X' \\b X \\hat{\\b\\beta}\n\\end{align}\n\\]\nTo minimise, we take the derivative in respect to \\(\\hat{\\b\\beta}\\), and set it equal to 0\n\\[\n\\begin{align}\n\\frac{\\partial SSR}{\\partial \\hat{\\b\\beta}} = -2 \\b X' \\b y + 2 \\b X\n\\b X \\hat{\\b\\beta} & = 0 \\\\\n2 \\b X' \\b X \\hat{\\b\\beta} & = 2 \\b X' \\b y \\\\\n\\hat{\\b\\beta} & = (2 \\b X' \\b X)^{-1} 2 \\b X' \\b y \\\\\n\\hat{\\b\\beta} & = (\\b X' \\b X)^{-1} \\b X' \\b y\n\\end{align}\n\\]\nWe have thus derived the OLS estimates for \\(\\hat\\b\\beta\\).\n\n\n\n\n\n\n\n\n\n\nAppendix B: Unbiasedness of OLS\n\n\n\n\n\n\nOLS can be shown to be an unbiased estimator of the relationship between two variables under the condition of strict exogeneity: \\(\\E(\\b\\eps | \\b X = \\b\\beta)\\).\n\nViolations of exogeneity are caused by omitted variables. If conditional ignorability is met, exogeneity should be met.\n\nStart with our OLS solution from appendix A, and modify as follows:\n\\[\n\\begin{align}\n\\hat{\\b\\beta} & = (\\b X' \\b X)^{-1} \\b X' \\b y \\\\\n& = (\\b X' \\b X)^{-1} \\b X'(\\b{X\\beta} + \\b \\eps) \\\\\n& = (\\b X' \\b X)^{-1} \\b X' \\b X \\b\\beta + (\\b X' \\b X)^{-1} \\b X'\\b\\eps \\\\\n& = \\b\\beta + (\\b X' \\b X)^{-1} \\b X'\\b\\eps\n\\end{align}\n\\]\nNow, let us find the expected value of our OLS estimator. For it to be unbiased, we should expect the expected value of our estimator, \\(\\E \\hat{\\b\\beta}\\), should equal the true parameter value \\(\\b\\beta\\).\n\\[\n\\begin{align}\n\\E(\\hat\\beta|\\b X) & = \\E((\\b\\beta + \\b X' \\b X)^{-1} \\b X'\\b\\eps) \\\\\n& = \\b\\beta + (\\b X' \\b X)^{-1} \\E(\\b \\eps | \\b X)\n\\end{align}\n\\]\nUsing the condition of strict exogeneity \\(\\E(\\b\\eps | \\b X = \\b\\beta)\\), we simplify to:\n\\[\n\\E(\\hat\\beta|\\b X) = \\b\\beta\n\\]\nNow, with the law of iterated expectations, we can show:\n\\[\n\\E\\hat{\\b\\beta} = \\b\\beta\n\\]\n\n\n\n\n\n\n\n\n\n\nAppendix C: OLS Bias under Heterogeneity\n\n\n\n\n\n\nFrom the selection on observables overview, we know that our causal effect is a weighted average:\n\\[\n\\tau_{ATE} = \\sum\\tau (\\b x) Pr(\\b x)\n\\]\nNotice how the weights are the probability of the confounder values of \\(\\b x\\).\nWith some complex math (Angrist 1998), we can actually show that OLS actually estimates:\n\\[\n\\hat\\beta_{OLS} = \\sum \\tau(\\b x) \\frac{\\V(D_i | \\b x)Pr(\\b x)}{\\sum \\V(D_i | \\b x^c)Pr(\\b x^c)}\n\\]\nWhere \\(\\b x^c\\) is the complement (not \\(\\b x\\)).\nNotice how the weights are not equivalent. They are only equivalent if there is homogeneity. This is the reason why OLS under heterogeneity is not properly estimating our ATE.\nWe can further explore what OLS is estimating. Słoczyński (2022) finds that OLS is actually unbiasedly estimating a weighted average of the ATT and ATU (effect on the untreated);\n\\[\n\\tau_{OLS} = w_1 \\tau_{ATT} + w_0 \\tau_{ATU}\n\\]\nWhere the weight for the ATT is defined as:\n\\[\nw_1 = \\frac{(1 - Pr(D = 1)) \\V(\\pi(X)|D = 0)}{Pr(D= 1) \\V(\\pi(X)|D=1) + (1-Pr(D=1)) \\V(\\pi(x)|D=0)}\n\\]\nwhere \\(\\pi(X)\\) is the propensity score of being treated. The ATU weight is the complement:\n\\[\nw_0 = 1 - w_1\n\\]",
    "crumbs": [
      "Selection on Observables",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fully Interacted Estimator</span>"
    ]
  },
  {
    "objectID": "distance.html",
    "href": "distance.html",
    "title": "Distance Matching",
    "section": "",
    "text": "See here on how selection on observables works, and the other estimators available.\n\nMia is in our study and receives the treatment. Mia’s causal effect is:\n\\[\n\\tau_{\\text{Mia}} = \\textcolor{purple}{Y^{(1)}_\\text{Mia}} - \\textcolor{red}{Y^{(0)}_\\text{Mia}}\n\\]\nWe cannot observe Mia’s counterfactual (in red). However, what we can do is to find an untreated individual similar to Mia to approximate Mia’s counterfactual:\n\\[\n\\tau_{\\text{Mia}} \\approx \\textcolor{purple}{Y^{(1)}_\\text{Mia}} - \\textcolor{purple}{Y^{(0)}_\\text{Matched individual}}\n\\]\nDistance matching matches an individual that is treated (like Mia) with one that is not treated based on how close their confounding values are. We define closeness by Mahalanobis distance:\n\\[\n\\delta_{i, j} = \\sqrt{(\\b x_i - \\b x_j)' \\ \\b\\Sigma_x^{-1} (\\b x_i - \\b x_j)}\n\\]\n\nWhere \\(i\\) and \\(j\\) are two units we want to measure the distance between, \\(\\b x\\) is a vector of confounder values, and \\(\\b\\Sigma_x\\) is the covariance matrix of confounders.\n\n\n\n\n\n\n\n\nKevin’s Estimator Score:  (2/5)\n\nDistance matching performs worse than genetic matching. However it is much quicker to estimate, so in larger datasets, you might consider to use distance matching.\nYou should not use distance matching on any dataset with more than 4 confounders, as it is badly biased by the curse of dimensionality.\nAll matching methods are data inefficient - they will throw out unmatched data, and this can greatly reduce our sample sizes.\nMatching is non-parametric, so it does not assume a linear relationship like regression.\n\n\n\n\n\nBefore you implement distance matching, make sure you have reasons to believe you meet the neccessary assumptions for selection on observables.\nWe will need the Matching package.\n\nlibrary(Matching)\n\nNow, we can implement the matching as follows.\n\natt &lt;- Match(Y = my_data$Y,\n             Tr = my_data$D,\n             X = my_data[,c(\"X1\",\"X2\", \"X3\")],\n             M = 1,\n             BiasAdjust = TRUE,\n             Weight = 2)\nsummary(att)\n\nOur output estimate will be the ATT - the average treatment effect for those units who received the treatment.",
    "crumbs": [
      "Selection on Observables",
      "Distance Matching"
    ]
  },
  {
    "objectID": "pscore.html",
    "href": "pscore.html",
    "title": "Propensity Score Matching",
    "section": "",
    "text": "See here on how selection on observables works, and the other estimators available.\n\nMia is in our study and receives the treatment. Mia’s causal effect is:\n\\[\n\\tau_{\\text{Mia}} = \\textcolor{purple}{Y^{(1)}_\\text{Mia}} - \\textcolor{red}{Y^{(0)}_\\text{Mia}}\n\\]\nWe cannot observe Mia’s counterfactual (in red). However, what we can do is to find an untreated individual similar to Mia to approximate Mia’s counterfactual:\n\\[\n\\tau_{\\text{Mia}} \\approx \\textcolor{purple}{Y^{(1)}_\\text{Mia}} - \\textcolor{purple}{Y^{(0)}_\\text{Matched individual}}\n\\]\nPropensity Score Matching matches an individual that is treated (like Mia) with one that is not treated based on how similar their likelihoods of treatment are.\nWhat is a likelihood of treatment? Well we know confounders cause people to get the treatment or not treatment. Thus, using an individual’s confounder values, we can estimate their likelihood of getting treatment, called a propensity score.\n\\[\n\\text{propensity score } \\pi =Pr(\\text{you get treated})\n\\]\n\nPropensity scores are typically estimated with a logistic regression, although in recent years, more researchers have started to use machine learning methods.\n\n\n\n\n\n\n\n\nKevin’s Estimator Score:  (2/5)\n\nPropensity score matching performs worse than genetic matching. However it is much quicker to estimate, so in larger datasets, you might consider to use distance matching.\nYou should not use propensity score matching on small datasets, as it can be badly biased, as the logistic regression used to estimate propensity scores relies on asymptotic consistency.\nAll matching methods are data inefficient - they will throw out unmatched data, and this can greatly reduce our sample sizes.\nMatching is non-parametric, so it does not assume a linear relationship like regression.\n\n\nThere are also some (advanced) criticisms of propensity score matching outlined here.\n\n\n\n\n\nBefore you implement propensity score matching, make sure you have reasons to believe you meet the neccessary assumptions for selection on observables:\nWe will need the Matching package.\n\nlibrary(Matching)\n\nFirst, we need to estimate the propensity scores with a logistic regression:\n\npropensity &lt;- glm(D ~ X1 + X2,\n                  data = my_data,\n                  family = \"binomial\")\nmy_data$pscore &lt;- predict(propensity,\n                          type = \"response\")\n\n\nA random forest model is also possible, but less common.\n\nNow, we can implement the matching as follows.\n\natt &lt;- Match(Y = my_data$Y,\n             Tr = my_data$D,\n             X = my_data[,\"pscore\"],\n             M = 1,\n             BiasAdjust = TRUE,\n             Weight = 2)\nsummary(att)\n\nOur output estimate will be the ATT - the average treatment effect for those units who received the treatment.",
    "crumbs": [
      "Selection on Observables",
      "Propensity Score Matching"
    ]
  },
  {
    "objectID": "genetic.html",
    "href": "genetic.html",
    "title": "Genetic Matching",
    "section": "",
    "text": "See here on how selection on observables works, and the other estimators available.\n\nMia is in our study and receives the treatment. Mia’s causal effect is:\n\\[\n\\tau_{\\text{Mia}} = \\textcolor{purple}{Y^{(1)}_\\text{Mia}} - \\textcolor{red}{Y^{(0)}_\\text{Mia}}\n\\]\nWe cannot observe Mia’s counterfactual (in red). However, what we can do is to find an untreated individual similar to Mia to approximate Mia’s counterfactual:\n\\[\n\\tau_{\\text{Mia}} \\approx \\textcolor{purple}{Y^{(1)}_\\text{Mia}} - \\textcolor{purple}{Y^{(0)}_\\text{Matched individual}}\n\\]\nLike distance matching, genetic matching matches an individual that is treated (like Mia) with one that is not treated based on how close their confounding values are. However, genetic matching uses a slightly different variation of mahalanobis distance:\n\\[\n\\delta_{i, j}(\\b W) = \\sqrt{(\\b x_i - \\b x_j)' \\ (\\b\\Sigma_x^{-\\frac{1}{2}})' \\ \\b W \\ \\b\\Sigma_x^{-\\frac{1}{2}}  (\\b x_i - \\b x_j)}\n\\]\n\nWhere \\(i\\) and \\(j\\) are two units we want to measure the distance between, \\(\\b x\\) are their confounder values, and \\(\\b\\Sigma_x\\) is the covariance matrix of confounders. \\(\\b W\\) is a weights matrix.\n\nThe weights \\(\\b W\\) are estimated to make the treated and untreated groups as similar as possible. Then, matching is done with the units that have the smallest distance.\n\n\n\n\n\n\n\nKevin’s Estimator Score:  (4/5)\n\nGenetic matching is the best performing matching estimator. However, genetic matching is also more computationally intensive, so for large data sets, propensity score matching might be quicker.\nAll matching methods are data inefficient - they will throw out unmatched data, and this can greatly reduce our sample sizes.\nMatching is non-parametric, so it does not assume a linear relationship like regression.\n\n\n\n\n\nBefore you start genetic matching, make sure you have reasons to believe you meet the neccessary assumptions for selection on observables:\nWe will need the Matching and MatchIt package.\n\nlibrary(Matching)\n\nFirst, we need to estimate the propensity scores with a logistic regression.\n\nIt is recommended to use the propensity score as one of the controls on which to genetic match on.\n\n\npropensity &lt;- glm(D ~ X1 + X2,\n                  data = my_data,\n                  family = \"binomial\")\nmy_data$pscore &lt;- predict(propensity,\n                          type = \"response\")\n\nThen, we use the GenMatch() function to estimate a weights matrix \\(\\b W\\):\n\nset.seed(333) #any number works\ngen &lt;- GenMatch(Tr = my_data$D,\n                    X = my_data[,c(\"X1\",\"X2\",\"pscore\")],\n                    BalanceMatrix = my_data[,c(\"X1\",\"X2\")],   \n                    estimand = \"ATT\",\n                    M = 2,\n                    replace = TRUE,\n                    ties = FALSE,\n                    distance.tolerance = 0,\n                    print.level = 0,\n                    pop.size = 200)\n\n\nYou can increase pop.size to increase the accuracy - but it will increase the time and computational power needed.\n\nNow, let us conduct estimation with genetic matching:\n\natt &lt;- Match(Y = my_data$Y,\n             Tr = my_data$D,\n             X = my_data[,c(\"X1\",\"X2\",\"pscore\")],\n             estimand = \"ATT\",\n             M = 2,\n             replace = TRUE,\n             ties = FALSE,\n             distance.tolerance = 0,\n             Weight.matrix = gen$Weight.matrix,\n             Weight = 3)\n\nOur output estimate will be the ATT - the average treatment effect for those units who received the treatment.",
    "crumbs": [
      "Selection on Observables",
      "Genetic Matching"
    ]
  },
  {
    "objectID": "weighting.html",
    "href": "weighting.html",
    "title": "Inverse Probability Weighting",
    "section": "",
    "text": "See here on how selection on observables works, and the other estimators available.\n\nLet us look at this example, with a confounder.\n\n\n\n\n\n\n\n\nexample2\n\n\n\nD\n\nReceiving Scholarship\n\n\n\nY\n\nUniversity Grades\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\nX\n\nSmartness (Confounder)\n\n\n\nX-&gt;D\n\n\n\n\n\nX-&gt;Y\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s pretend there are only dumb and smart people (for simplicity). Our treated and control groups might be:\n\n\n\n\n\n\n\nTreated (Got Scholarship)\nUntreated (Did not get scholarship)\n\n\nSmart Students (x4)\nSmart Students (x1)\n\n\nDumb Students (x1)\nDumb Students (x4)\n\n\n\nOur two groups have pre-existing differences. However, by emphasising certain individuals, we can make it seem like there are no more imbalances. For example, weighting might make our above table become:\n\n\n\n\n\n\n\nTreated (Got Scholarship)\nUntreated (Did not get scholarship)\n\n\nSmart Students (x4)\nSmart Students (emphasise to x4)\n\n\nDumb Students (emphasise to x4)\nDumb Students (x4)\n\n\n\n\nSee how the underrepresented individuals in each group (treated/untreated) were weighted upwards. More technically, inverse probability weighting emphasises/weights an individual by the inverse of their likelihood to receive treatment.\n\nWe can see there is no more pre-existing differences after weighting.\n\n\n\n\n\n\n\nKevin’s Estimator Score:  (3/5)\n\nWeighting is relatively good in large sample sizes.\nYou should not use weighting when with small samples, since their can be noticable bias, as the method is very sensitive to outlier propensity scores.\nWeighting is more efficient with data than matching as it does not throw out unmatched observations like matching estimators do.\nWeighting is non-parametric, so it does not assume a linear relationship like regression.\n\n\n\n\n\nBefore you inverse probability weighting, make sure you have reasons to believe you meet the neccessary assumptions for selection on observables:\nWe will need the estimatr package:\n\nlibrary(estimatr)\n\nTo estimate the propensity scores and weights, we can use the glm() command:\n\npropensity &lt;- glm(D ~ X1 + X2,\n                  data = my_data,\n                  family = \"binomial\")\nmy_data$pscore &lt;- predict(propensity, type = \"response\")\nmy_data$ipw &lt;- ifelse(mydata$D == 1,\n                      1/my_data$pscore,\n                      1/(1-my_data$pscore))\n\nFinally, we need to use the lm_robust() command to estimate our causal effects:\n\nate &lt;- estimatr::lm_robust(Y ~ D, data = my_data, weights = ipw)\nsummary(ate)\n\nThe output will be the ATE - the average treatment effect for all units in the study.",
    "crumbs": [
      "Selection on Observables",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Inverse Probability Weighting</span>"
    ]
  },
  {
    "objectID": "rdd.html",
    "href": "rdd.html",
    "title": "Regression Discontinuity",
    "section": "",
    "text": "Coming soon",
    "crumbs": [
      "Regression Discontinuity"
    ]
  },
  {
    "objectID": "frameworks.html",
    "href": "frameworks.html",
    "title": "Causal Inference Basics",
    "section": "",
    "text": "This page covers the potential outcomes framework and the causal estimands.\n\nIn causal inference, we are interested in causal questions:\n\n\n\n\n\n\n\n\nexample1\n\n\n\nD\n\nTreatment (D)\n\n\n\nY\n\nOutcome (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\n\n\n\n\n\n\n\nWe generally assume the treatment \\(D\\) is binary.\n\nImagine we have two hypothetical parallel worlds that are copies of each other. Both of these worlds are identical except for one aspect: the treatment:\n\n\n\n\n\n\n\n\nParallel World\nTreatment\nPotential Outcome\n\n\nKevin does not Receive Treatment\n\\(D_\\text{Kevin} = 0\\)\n\\(\\purple{Y_\\text{Kevin}^{(0)}}\\)\n\n\nKevin Receives Treatment\n\\(D_\\text{Kevin} = 1\\)\n\\(\\purple{Y_\\text{Kevin}^{(1)}}\\)\n\n\n\n\nThe only difference between the two worlds is the treatment. Thus, any difference in outcomes between the two worlds must be the causal effect of the treatment.\n\\[\n\\tau_\\text{Kevin} = \\purple{Y_\\text{Kevin}^{(1)}} - \\purple{Y_\\text{Kevin}^{(0)}}\n\\]\n\nTechnically, we need another assumption, SUTVA, for this to be true. I will explain this assumption as part of the identification assumptions.\n\nHowever, in reality, we do not have two parallel worlds. Thus, by definition, one of the potential outcomes is not observed in our real world - the counterfactual.\n\n\n\n\n\n\n\n\nIn the Real World\nObserved Outcome\nCounterfactual\n\n\nKevin receives treatment (treated)\n\\(Y_\\text{Kevin}= \\purple{Y_\\text{Kevin}^{(1)}}\\)\n\\(\\red{Y_\\text{Kevin}^{(0)}}\\)\n\n\nKevin did not receive treatment (untreated)\n\\(Y_\\text{Kevin} = \\purple{Y_\\text{Kevin}^{(0)}}\\)\n\\(\\red{Y_\\text{Kevin}^{(1)}}\\)\n\n\n\n\nThe fundamental problem of causal inference is that in order to calculate our individual treatment effect \\(\\tau\\), we need both potential outcomes. Our goal is to estimate causal effects without observing counterfactuals. This is difficult at the individual level, so instead, we focus on average treatment effects for groups:\n\n\n\n\n\n\n\n\nGroup Effects\nNotation\nDefinition\n\n\nAverage Treatment Effect (ATE)\n\\(\\tau_\\text{ATE}\\)\nThe average treatment effects for all individuals in our study (treated and untreated).\n\n\nAverage Treatment Effect on the Treated (ATT)\n\\(\\tau_\\text{ATT}\\)\nThe average treatment effect but only for individuals who receive the treatment in our study.\n\n\nLocal Average Treatment Effect (LATE)\n\\(\\tau_\\text{LATE}\\)\nThe average treatment effect but only for a specific (local) group of individuals in a study.",
    "crumbs": [
      "Causal Inference Basics"
    ]
  },
  {
    "objectID": "soo.html",
    "href": "soo.html",
    "title": "Selection on Observables",
    "section": "",
    "text": "This is an overview of selection on observables. For estimators and R-code, use the sidebar.\n\nOur issue in causal inference is that a confounder is causing pre-existing differences:\n\n\n\n\n\n\n\n\nexample2\n\n\n\nD\n\nReceiving Scholarship\n\n\n\nY\n\nUniversity Grades\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\nX\n\nIntellegence (Confounder)\n\n\n\nX-&gt;D\n\n\n\n\n\nX-&gt;Y\n\n\n\n\n\n\n\n\n\n\n\n\nBy definition, as the confounder changes, your likelihood of getting treatment changes. As the confounder changes, the outcome value will also change.\nThese issues occur when the confounder changes in value. So what if we hold the confounders constant? Let’s assume that intellegence has two values: smart and dumb. Let us calculate the treatment effect within each level of intellegence:\n\\[\n\\tau_\\text{smart} = \\purple{\\mean Y_\\text{smart}^{(1)}} - \\purple{\\mean Y_\\text{smart}^{(0)}}\n, \\quad \\tau_\\text{dumb} = \\purple{\\mean Y_\\text{dumb}^{(1)}} - \\purple{\\mean Y_\\text{dumb}^{(0)}}\n\\]\n\nObviously, most confounders will not have only 2 values. But the same intuition applies - for each value of confounders, we split all individuals into groups, and calculate the average treatment effect within each group.\n\nThe confounder is constant here, so no selection bias. Thus, within each category, correlation is equal to causation. Our overall causal effect will be a weighted average of the categories:\n\\[\n\\tau = \\tau_\\text{smart} Pr(\\text{smart})  \\ + \\ \\tau_\\text{dumb} Pr(\\text{dumb})\n\\]\n\nThe weights of this weighted average are the probability/frequency of that value of the confounder. A more formal proof is provided in the appendix.\n\nFor selection on observables to work, we need to meet 3 assumptions:\n\n\n\n\n\n\n\nAssumption\nDescription\n\n\nConditional Ignorability\nThis means that we must account for all possible confounders (cannot miss a single one).\n\n\nCommon Support\nThis means no one can have a 100% chance of being in treatment or control. They always have a chance to be in either, no matter their confounding values.\n\n\nStable Unit Treatment Value Assumption (SUTVA)\nThis means that if Ava is treated, that does not affect Mia’s outcome (and for any other 2 individuals).\n\n\n\n\nA more formal definition of these assumptions is provided in the appendix.\n\nWe have a wide choice of estimators that we can use.\n\n\n\n\n\n\n\nEstimator\nKevin’s Rating\n\n\nFully Interacted Estimator\n\n\n\n\n\nDistance Matching\n\n\n\n\n\nPropensity Score Matching\n\n\n\n\n\nGenetic Matching\n\n\n\n\n\nInverse Probability Weighting\n\n\n\n\n\n\n\nImportant: You should not always go for the higher rated estimator. Each estimator has its strengths/weaknesses, which the links for each page explain in more detail.\n\nUse the sidebar or links in the table to access each estimator’s page.\n\n\nAppendix\n\n\n\n\n\n\nAppendix A: Formal Definition of Assumptions\n\n\n\n\n\n\nConditional ignorability is the assumption that among units \\(i\\) with identical confounder values \\(\\b X_i = \\b x\\), treatment \\(D_i\\) is as-if randomly assigned. This also means potential outcomes are independent from treatment given \\(\\b X_i\\).\n\\[\n(\\C, \\T) \\ind D_t \\ | \\ \\b X_i = \\b x\n\\]\nThis assumption implies the following:\n\\[\n\\begin{align}\n& \\E(\\C | D_i = 1, \\b X_i = \\b x) = \\E(\\C | D_i = 0, \\b X_i = \\b x) = \\E(\\C | \\b X_i = \\b x) \\\\\n& \\E(\\T | D_i = 1, \\b X_i = \\b x) = \\E(\\T | D_i = 0, \\b X_i = \\b x) = \\E(\\T | \\b X_i = \\b x)\n\\end{align}\n\\]\nCommon Support implies that for any unit \\(i\\) with any value of confounders, they have a non-zero probability they can be assigned to both treatment and control.\n\\[\n0 &lt; Pr(D_i = 1 | \\b X_i = \\b x) &lt; 1\n\\]\nFor all possible confounder values \\(\\b x\\).\n\n\n\n\n\n\n\n\n\n\nAppendix B: Identification Proof of ATE\n\n\n\n\n\n\nBe sure to see appendix A before starting this.\nLet us first find the conditional ATE, conditional on a specific confounder value \\(\\b x\\):\n\\[\n\\begin{align}\n\\tau(\\b x) & = \\E(\\T - \\C) | \\b X_i = \\b x) \\\\\n& = \\E(\\T | \\b X_i = \\b x) - \\E(\\C | \\b X_i = \\b x)\n\\end{align}\n\\]\nNow, from the properties implied by conditional ignorability from appendix A, we get:\n\\[\n\\begin{align}\n\\tau(\\b x) & = \\E(\\T | D_i = 1, \\b X_i = \\b x) - \\E(\\C | D_i = 0, \\b X_i = \\b x) \\\\\n& = \\E(Y_i | D_i = 1, \\b X_i = \\b x) - \\E(Y_i |D_i = 0, \\b X_i = \\b x\n\\end{align}\n\\]\nNow, we can see under conditional ignorability, the conditional ATE is identifiable as all quantities are observed.\nNow, let us consider the definition of the ATE - which is a weighted average of all conditional ATE’s:\n\\[\n\\tau_{ATE} = \\int \\tau(\\b x) \\ d Pr(\\b x)\n\\]\nWe already know we can identify \\(\\tau(\\b x)\\). So, that means we have all we need to identify the ATE.\n\n\n\n\n\n\n\n\n\n\nAppendix C: Identification Proof of ATT\n\n\n\n\n\n\nBe sure to see appendix A before starting this.\nLet us first find the conditional ATE, conditional on a specific confounder value \\(\\b x\\):\n\\[\n\\begin{align}\n\\tau(\\b x) & = \\E(\\T - \\C) | \\b X_i = \\b x) \\\\\n& = \\E(\\T | \\b X_i = \\b x) - \\E(\\C | \\b X_i = \\b x)\n\\end{align}\n\\]\nNow, from the properties implied by conditional ignorability from appendix A, we get:\n\\[\n\\begin{align}\n\\tau(\\b x) & = \\E(\\T | D_i = 1, \\b X_i = \\b x) - \\E(\\C | D_i = 0, \\b X_i = \\b x) \\\\\n& = \\E(Y_i | D_i = 1, \\b X_i = \\b x) - \\E(Y_i |D_i = 0, \\b X_i = \\b x\n\\end{align}\n\\]\nNow, we can see under conditional ignorability, the conditional ATE is identifiable as all quantities are observed.\nNow, let us consider the definition of the ATT - which is a weighted average of all conditional ATE’s but only for treated individuals.\n\\[\n\\tau_{ATE} = \\int \\tau(\\b x) \\ d Pr(\\b x| D_i = 1)\n\\]\nWe already know we can identify \\(\\tau(\\b x)\\). So, that means we have all we need to identify the ATT.",
    "crumbs": [
      "Selection on Observables"
    ]
  },
  {
    "objectID": "latent.html",
    "href": "latent.html",
    "title": "Latent Variable Models",
    "section": "",
    "text": "This is an overview of latent variable models. For specific models and R-code, use the sidebar.\n\nA latent variable model connects a unobserved variable (latent factor) with a few observed variables (items) that are considered imperfect measures of the latent factor.\n\n\n\n\n\n\n\n\nexample2\n\n\n\nF\n\nLatent Factor (F)\n\n\n\nX1\n\nItem 1 (X1)\n\n\n\nF-&gt;X1\n\n\nλ\n\n\n\nX2\n\nItem 2 (X2)\n\n\n\nF-&gt;X2\n\n\nλ\n\n\n\nX3\n\nItem 3 (X3)\n\n\n\nF-&gt;X3\n\n\nλ\n\n\n\n\n\n\n\n\n\n\nFor example, maybe we want to measure the political ideology of a senator. We cannot directly observe the political ideology (the latent factor), but we can observe how they vote on different bills (the items)\n\nLatent variable models assume we can model the relationship between each observed item and the latent factor with some sort of regression model. The coefficient of each regression (often denoted \\(\\lambda\\)) is the relationship between each item and the factor.\n\nFor example, in the figure above, each item (X1, X2, X3) is related to the factor (F) with by a \\(\\lambda\\) coefficient.\n\nThese \\(\\lambda\\) are called factor loadings. We can interpret the estimated factor loadings \\(\\widehat\\lambda\\) to interpret what the unobserved factor actually is measuring.\n\nFor example, if a factor has a strong relationship with one item, and a weaker relationship with another item, we might conclude that the factor measures the first item more than the second item.\n\nWe can also use latent variable models to create factor scores \\(\\widetilde F_i\\), which are basically actual values of the latent variable for each individual \\(i\\) in our data. This allows us to use the latent variable in other statistical models.\nThe choice of latent variable model depends on the type of items/factors:\n\n\n\n\n\n\n\n\nModel\nFactor Type\nItem Type\n\n\nFactor Analysis\nContinuous\nContinuous\n\n\nItem Response Theory\nContinous\nCategorical/Binary\n\n\nStructural Class Models\nCategorical/Binary\nCategorical/Binary\n\n\n\n\nSince latent variable models are estimated with maximum likelihood estimation, they have hypothesis tests and summary measures like any other MLE estimated model.\nSo far, this introduction has assumed just one latent variable factor. However, all models allow for multiple factors as well. If we have many items, some items might only measure on factor, others both factors.\nEach latent model also has the ability to conduct confirmatory analysis. This is basically when we, based on theoretical reasons (such as reading the literature), impose certain restrictions on models, and test if this hypothesised model is good.\n\nThis typically takes the form of setting certain factor loadings \\(\\lambda\\) to 0, meaning a certain item does not measure one of the factors.\n\nWe can also combine different structural models together to form structural equation models. For example, we might want to find the relationship between two latent variables. This implies some regression model between them. A structural equation model estimates this regression, alongside multiple latent measurement models, all together.",
    "crumbs": [
      "Latent Variable Models"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "Welcome\nThis is a collection of resources on political science and political economy methodology that I have collected throughout my postgraduate degree at the London School of Economics. I hope this resource can be useful to both myself and others!\nThe resources in this collection include:\n\nCausal inference, including details (and modern advancements) in difference-in-differences, regression discontinuity, and selection on observables.\nSome general content on statistical models.\n\nThe sidebar/menu contains parts. Each part contains an overview, and several follow-up pages regarding specific estimators/topics.\n\nNotation note: As with most causal inference notation, I will use capital letters to reference variables (such as treatment, outcome).\nI will use vectors/matrices for shortening regression equations. Because I am using capital letters to refer to variables, some vectors might be capitalised - which does not follow normal mathematical notation. Example: \\(\\b X_i\\) might be a vector of confounder values for unit \\(i\\).",
    "crumbs": [
      "Welcome"
    ]
  }
]