[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kevin’s PSPE Resources",
    "section": "",
    "text": "Welcome\nThis is a collection of resources and notes for political science and political economy that I have collected throughout my postgraduate degree at the London School of Economics.\nThe resources in this collection include:\n\nCausal inference, including details (and modern advancements) on differences-in-differences, regression discontinuity, and selection on observables.\nSome general content covering regression models.\nSome content on latent variable (multivariate) models, like factor analysis.\n\nI am continuously adding more to this collection as a learn more. Some parts may be incomplete, and you may see some changes in existing parts.\nThis isn’t meant to teach you stuff - more of a supplement + review + implementation guide so don’t use it to self-learn that might not work as well.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "frameworks.html#footnotes",
    "href": "frameworks.html#footnotes",
    "title": "Potential Outcomes",
    "section": "",
    "text": "Technically, the stable unit treatment value assumption (SUTVA) is required for this to be true.↩︎",
    "crumbs": [
      "Causal Inference Basics",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Potential Outcomes</span>"
    ]
  },
  {
    "objectID": "correlation.html#footnotes",
    "href": "correlation.html#footnotes",
    "title": "Issue of Selection Bias",
    "section": "",
    "text": "Correlation is the difference in observed outcomes: \\(\\mean Y_\\text{treated} - \\mean Y_\\text{untreated}\\)↩︎\nSmoking is not the only possible confounder, we just use it as an example. Drinking, age, etc. are all other potential confounders.↩︎",
    "crumbs": [
      "Causal Inference Basics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Issue of Selection Bias</span>"
    ]
  },
  {
    "objectID": "randomisation.html#footnotes",
    "href": "randomisation.html#footnotes",
    "title": "The Magic of Randomisation",
    "section": "",
    "text": "Smartness is not the only confounder. Other confounders could be family income, athletic ability, etc.↩︎",
    "crumbs": [
      "Causal Inference Basics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Magic of Randomisation</span>"
    ]
  },
  {
    "objectID": "did.html",
    "href": "did.html",
    "title": "Differences-in-Differences",
    "section": "",
    "text": "Differences-in-Differences is a popular design, used when all individuals are untreated in one year, and some individuals get treated the next year.\n\n  Validity:  (3/5)\n\n\n  Interpretability:   (4/5)",
    "crumbs": [
      "Classical DiD",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Differences-in-Differences</span>"
    ]
  },
  {
    "objectID": "rdd.html",
    "href": "rdd.html",
    "title": "Regression Discontinuity",
    "section": "",
    "text": "(Sharp) Regression Discontinuity is a popular design, used when treatment is assigned based on being above or below a cutoff.\n\n  Validity:  (4/5)\n\n\n  Interpretability:   (3/5)",
    "crumbs": [
      "Regression Discontinuity",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Regression Discontinuity</span>"
    ]
  },
  {
    "objectID": "fuzzy.html",
    "href": "fuzzy.html",
    "title": "Fuzzy Discontinuity",
    "section": "",
    "text": "Fuzzy Regression Discontinuity is a design used when treatment is influenced, but not perfectly determined, by being above or below a cutoff.\n\n  Validity:  (3/5)\n\n\n  Interpretability:   (1/5)",
    "crumbs": [
      "Regression Discontinuity",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Fuzzy Discontinuity</span>"
    ]
  },
  {
    "objectID": "matching.html",
    "href": "matching.html",
    "title": "How Matching Works",
    "section": "",
    "text": "Mia is in our study and receives the treatment. Mia’s individual causal effect is:\n\\[\n\\tau_{\\text{Mia}} = \\textcolor{purple}{Y^{(1)}_\\text{Mia}} - \\textcolor{red}{Y^{(0)}_\\text{Mia}}\n\\]\n\n\nThe counterfactual in red is unobserved.\nSince Mia receives the treatment in real life, we cannot observe the counterfactual where Mia does not get the treatment. However, we can estimate Mia’s counterfactual by finding someone else in our study, who did not receive the treatment, but is also really similar to Mia in all other ways.\nLet’s say Ava is really similar to Mia. Ava also happens to have not received the treatment. We can approximate Mia’s counterfactual using Ava’s observed outcome:\n\\[\n\\textcolor{red}{Y^{(0)}_\\text{Mia}} \\approx \\textcolor{purple}{Y^{(0)}_\\text{Ava}}\n\\]\nHaving approximated Mia’s counterfactual, we can now estimate Mia’s causal effect, as both quantities are observed:\n\\[\n\\widehat\\tau_{\\text{Mia}} = \\textcolor{purple}{Y^{(1)}_\\text{Mia}} - \\textcolor{purple}{Y^{(0)}_\\text{Ava}} = Y_\\text{Mia} - Y_\\text{Ava}\n\\]\nWe can do the matching for every single person in the treatment group, then average all of these individual causal effects to get an estimate of the ATT.\nBy matching individuals with the same/very similar confounder values, we eliminate pre-existing differences, since our matched pairs will all be similar to each other. Thus, selection bias will not be a concern.\n\nFor matching to work, we must meet the following three assumptions:\n\n\n\n\n\n\n\n\n\n\n\nAssumption\nDescription\nHow to Check\n\n\n\n\nConditional Ignorability\nThis means that when we match, we must account for all possible confounders.\nWe can conduct balance checks.\n\n\nCommon Support\nThis means no one can have a 100% chance of being in treatment or control. They always have a chance to be in either, no matter their confounding values.\nHard to check. One way to sort of check is to see if you have a treated and untreated unit for every confounder value in your sample.\n\n\nStable Unit Treatment Value Assumption (SUTVA)\nThis means that if Ava is treated, that does not affect Mia’s outcome (and for any other 2 individuals).\nWe have to use our own theoretical reasoning.\n\n\n\n\n\nTable 1: Ensure all of these assumptions are met if you are using matching\n\n\n\n\nThere are three estimators to implement matching. These are essentially different ways to calculate which units are “closest” to each other for matching.\n\n\n\n\n\n\n\n\nEstimator\nKevin’s Rating\nWhen to Use\n\n\n\n\nDistance Matching\n\n\n\nWhen genetic matching is not possible, and we have less than 5 confounders and a small sample.\n\n\nPropensity Score Matching\n\n\n\nWhen genetic matching is not possible, and we have a large sample.\n\n\nGenetic Matching\n\n\n\nWhenever possible. Can require a good computer and take long for large data sets.\n\n\n\nUse the sidebar or links in the table to access each estimator’s page.",
    "crumbs": [
      "Selection on Observables",
      "How Matching Works"
    ]
  },
  {
    "objectID": "distance.html",
    "href": "distance.html",
    "title": "Distance Matching",
    "section": "",
    "text": "Distance matching matches an individual that is treated (like Mia) with one that is not treated based on how close their confounding values are. We define closeness by Mahalanobis distance:\n\\[\n\\delta_{i, j} = \\sqrt{(\\b x_i - \\b x_j)^\\top \\b\\Sigma_x^{-1} (\\b x_i - \\b x_j)}\n\\]\n\n\nWhere \\(i\\) and \\(j\\) are two units we want to measure the distance between, \\(\\b x\\) are their confounder values, and \\(\\b\\Sigma_x\\) is the covariance matrix of confounders.\nIt is basically a way to measure distance across multiple dimensions, adjusting for the scale at which confounders are measured. The treated and untreated units that have the smallest distance between them are matched together.\n\n\n\n\n\n\n\nKevin’s Estimator Score:  (2/5)\n\nDistance matching performs worse than genetic matching.\nDistance matching is much quicker and easier to estimate than genetic matching, so for large datasets, it is useful.\nYou should not use distance matching on any dataset with more than 4 confounders, as it is badly biased by the curse of dimensionality.\n\n\n\n\n\n\nTo implement distance matching, we will need the Matching package.\n\nlibrary(Matching)\n\nNow, we can implement the matching as follows.\n\natt &lt;- Match(Y = my_data$Y,\n             Tr = my_data$D,\n             X = my_data[,c(\"X1\",\"X2\", \"X3\")],\n             M = 1,\n             BiasAdjust = TRUE,\n             Weight = 2)\nsummary(att)\n\n\n\nBiasAdjust is a complex method that reduces the bias in matching due to imperfect matches. You can change M (number of matches per treated unit) for better matches.\nOur output estimate will be the ATT.",
    "crumbs": [
      "Selection on Observables",
      "Distance Matching"
    ]
  },
  {
    "objectID": "pscore.html",
    "href": "pscore.html",
    "title": "Propensity Score Matching",
    "section": "",
    "text": "Propensity Score Matching matches an individual that is treated (like Mia) with one that is not treated based on how similar their likelihoods of treatment are.\nWhat is a likelihood of treatment? Well we know confounders cause people to get the treatment or not treatment. Thus, using an individual’s confounder values, we can estimate their likelihood of getting treatment, called a propensity score.\n\\[\n\\text{propensity score } \\pi =Pr(\\text{you get treated})\n\\]\nThen, we match units based on how close they are in propensity scores.\n\n\n\n\n\n\n\nKevin’s Estimator Score:  (2/5)\n\nPropensity score matching performs worse than genetic matching.\nPropensity score matching is much quicker and easier to estimate than genetic matching, so for large datasets, it is useful.\nYou should not use propensity score matching on small datasets, as it can be badly biased.\nThere are also some criticisms of propensity score outlined here.\n\n\n\n\n\n\nTo implement propensity score matching, we will need the Matching package.\n\nlibrary(Matching)\n\nFirst, we need to estimate the propensity scores with a logistic regression:\n\npropensity &lt;- glm(D ~ X1 + X2,\n                  data = my_data,\n                  family = \"binomial\")\nmy_data$pscore &lt;- predict(propensity,\n                          type = \"response\")\n\n\n\nA random forest model is also possible, but less common.\nNow, we can implement the matching as follows.\n\natt &lt;- Match(Y = my_data$Y,\n             Tr = my_data$D,\n             X = my_data[,\"pscore\"],\n             M = 1,\n             BiasAdjust = TRUE,\n             Weight = 2)\nsummary(att)\n\n\n\nReplace Y with the outcome variable, D with the treatment variable.\nOur output estimate will be the ATT.",
    "crumbs": [
      "Selection on Observables",
      "Propensity Score Matching"
    ]
  },
  {
    "objectID": "genetic.html",
    "href": "genetic.html",
    "title": "Genetic Matching",
    "section": "",
    "text": "Like distance matching, genetic matching matches an individual that is treated (like Mia) with one that is not treated based on how close their confounding values are.\nHowever, instead of using a standard mahalanobis distance, genetic matching uses a mahalanobis distance that puts different weights/emphasis on different confounders:\n\\[\n\\delta_{i, j}(\\b W) = \\sqrt{(\\b x_i - \\b x_j)^\\top (\\b\\Sigma_x^{-1/2})^\\top \\b W \\b\\Sigma_x^{-1/2}  (\\b x_i - \\b x_j)}\n\\]\n\n\nWhere \\(i\\) and \\(j\\) are two units we want to measure the distance between, \\(\\b x\\) are their confounder values, and \\(\\b\\Sigma_x\\) is the covariance matrix of confounders. \\(\\b W\\) is a weights matrix.\nIt is basically a way to measure distance across multiple dimensions, adjusting for the scale at which confounders are measured, and weighting some confounders more.\nThe weights \\(\\b W\\) are estimated to make the treated and untreated groups as similar as possible. Then, matching is done with the units that have the smallest distance.\n\n\n\n\n\n\n\nKevin’s Estimator Score:  (4/5)\n\nGenetic matching has been shown by studies to be the best performing matching estimator.\nHowever, genetic matching is also more computationally intensive, so for large data sets, propensity score matching might be quicker.\n\n\n\n\n\n\nTo implement propensity score matching, we will need the Matching and MatchIt package.\n\nlibrary(Matching)\n\nFirst, we need to estimate the propensity scores with a logistic regression. It is recommended to use the propensity score as one of the controls on which to genetic match on.\n\npropensity &lt;- glm(D ~ X1 + X2,\n                  data = my_data,\n                  family = \"binomial\")\nmy_data$pscore &lt;- predict(propensity,\n                          type = \"response\")\n\nThen, we use the GenMatch() function to estimate a weights matrix \\(\\b W\\):\n\nset.seed(333) #any number works\ngen &lt;- GenMatch(Tr = my_data$D,\n                    X = my_data[,c(\"X1\",\"X2\",\"pscore\")],\n                    BalanceMatrix = my_data[,c(\"X1\",\"X2\")],   \n                    estimand = \"ATT\",\n                    M = 2,\n                    replace = TRUE,\n                    ties = FALSE,\n                    distance.tolerance = 0,\n                    print.level = 0,\n                    pop.size = 200)\n\n\n\nYou can increase pop.size to increase the accuracy - but it will increase the time and computational power needed.\nNow, let us conduct estimation with genetic matching:\n\natt &lt;- Match(Y = my_data$Y,\n             Tr = my_data$D,\n             X = my_data[,c(\"X1\",\"X2\",\"pscore\")],\n             estimand = \"ATT\",\n             M = 2,\n             replace = TRUE,\n             ties = FALSE,\n             distance.tolerance = 0,\n             Weight.matrix = gen$Weight.matrix,\n             Weight = 3)\n\nOur output will be the ATT.",
    "crumbs": [
      "Selection on Observables",
      "Genetic Matching"
    ]
  },
  {
    "objectID": "weighting.html",
    "href": "weighting.html",
    "title": "Weighting Estimator",
    "section": "",
    "text": "What is Inverse Probability Weighting?\nLet us look back at an earlier example from chapter 2:\nWe know we are concerned about confounders. Smoking is a potential confounder.\nLet’s pretend our smoking confounder has 2 categories: people who do not smoke, and frequent smokers. Let’s focus on the frequent smokers. We might have 5 frequent smokers in our study: Ava, Ben, Mia, Max, and Zoe. Because smoking makes you more likely to need to go to the hospital, their treatment statuses look like:\nThis is a clear selection bias issue - smoking is affecting who gets treated, and smoking also results in worse health outcomes. Inverse probability weighting is a solution to solve selection bias. It essentially emphaises certain individuals to “solve” selection bias.\nFor example, inverse probability weighting would “pretend” that the frequent smokers table from above actually looks like:\nBy emphasising Ben and making him worth 4 individuals (and doing something similar in the non-smoking category), inverse probability weighting has essentially solved the selection bias issue by making it so that confounders do not affect the likelihood of getting treatment.\nSince confounders influence the likelihood of an individual getting treatment, we can estimate that likelihood of getting treatment, given an individual’s confounder levels. Inverse probability weighting decides the weight/emphasis of every individual based on the inverse of their likelihood to receive treatment.",
    "crumbs": [
      "Selection on Observables",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Weighting Estimator</span>"
    ]
  },
  {
    "objectID": "weighting.html#what-is-inverse-probability-weighting",
    "href": "weighting.html#what-is-inverse-probability-weighting",
    "title": "Weighting Estimator",
    "section": "",
    "text": "example1\n\n\n\nD\n\nGoing to the Hospital\n\n\n\nY\n\nHealth Outcomes\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexample2\n\n\n\nD\n\nGoing to the Hospital\n\n\n\nY\n\nHealth Outcomes\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\nX\n\nSmoking (Confounder)\n\n\n\nX-&gt;D\n\n\n\n\n\nX-&gt;Y\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote: smoking is not the only possible confounder, we just use it as an example. Drinking, age, etc. are all other potential confounders. To find the causal effect, you must account for all confounders.\n\n\n\n\n\n\n\n\nTreated (Hospital)\nUntreated\n\n\n\n\nAva, Mia, Max, Zoe\nBen\n\n\n\n\n\nThe opposite is true for non-smokers: 4 of the 5 are in the untreated group, and only 1 of 5 are in the treated.\n\n\n\n\n\n\n\n\n\nTreated (Hospital)\nUntreated\n\n\n\n\nAva, Mia, Max, Zoe\nBen, Ben, Ben, Ben\n\n\n\n\n\n\n\nThe inverse of the likelihood of getting treatment means that individuals less likely to receive treatment will be weighted more, as shown with Ben above.",
    "crumbs": [
      "Selection on Observables",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Weighting Estimator</span>"
    ]
  },
  {
    "objectID": "weighting.html#when-should-you-use-this-method",
    "href": "weighting.html#when-should-you-use-this-method",
    "title": "Weighting Estimator",
    "section": "When Should You Use this Method?",
    "text": "When Should You Use this Method?\nWhen can/should you use weighting?\n\nIf none of random experiments, regression discontinuity (including fuzzy), differences-in-differences, or instrumental variables are possible.\nIf you have a large sample size (generally over 200 observations for both treated and untreated). If you have a smaller sample size, consider distance matching.\nYou are interested in the ATE instead of the ATT. If you want the ATT, consider matching.\nYou know and have data on all the confounders in question.\n\nThen, check you have met these assumptions:\n\nConditional Ignorability: we must know all confounders, and have data on all confounders, and include all confounders in our estimation.\nWe must have a sufficiently large sample size, as weighting is inaccurate in smaller sample sizes. We should have at least 200 observations per treatment group (treated and untreated). The more confounders you have, the larger sample you need.\n\n\nMy RatingsAdvantagesDisadvantages\n\n\n\n  Validity:   (2/5)\n\nHow convincing is this method at accurately estimating the true causal effects?\n\nIt is often difficult to justify that you have accounted for all possible confounders. The estimator is also biased in small samples, but big-data is pretty available these days.\nThis makes the design less convincing than all other methods, except matching which is about the same level of convincing.\nIt is often used when we cannot use other better methods.\n\n\n  Interpretability:   (5/5)\n\nHow useful are the results from this method?\n\nThe estimand is the ATE, probably the most generalisable effect summary.\n\n\n\nIf none of random experiments, instrumental variables, regression discontinuity, or differences-in-differences are possible, you generally resort to matching or weighting.\nWeighting does have some advantages over matching in some situations.\n\nWeighting uncovers the ATE, while matching can only uncover the ATT. Often, we are interested in the ATE, since the ATT is only the causal effects for people who received the treatment, when we are interested in what will happen when we expand a treatment to others.\nWeighting performs better with larger numbers of covariates, especially compared with distance matching.\n\n\n\nWeighting has disadvantages when compared to other methods.\n\nInverse probability weighting requires you to include every single confounder. This is often not possible. Sometimes, we just do not know enough about a topic to know all the confounders, or we know a confounder, but it is impossible to measure. Methods like random experiments, instrumental variables, regression discontinuity, or differences-in-differences can find causal effects without knowing all confounders.\nInverse probability weighting can be very inaccurate with small samples. This is because the estimator becomes very sensitive to extreme propensity score values, which occurs more often in small samples. In small samples, distance matching is more accurate.",
    "crumbs": [
      "Selection on Observables",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Weighting Estimator</span>"
    ]
  },
  {
    "objectID": "weighting.html#implementing-inverse-probability-weighting",
    "href": "weighting.html#implementing-inverse-probability-weighting",
    "title": "Weighting Estimator",
    "section": "Implementing Inverse Probability Weighting",
    "text": "Implementing Inverse Probability Weighting\nTo implement inverse probability weighting, we need to first estimate our propensity scores (likelihood of an individual being treated based on their confounders). The propensity scores will be needed as part of the calculation of weights/emphasis for each individual.\n\n\n\n\n\n\nWe must use all confounders in our prediction of propensity scores. If we leave out any possible confounder, our predicted likelihood of treatment values will be wrong, and our causal estimates will be wrong.\n\n\n\nBefore we start, we will need the MatchIt and estimatr packages. If you never have installed the packages, you should install them. Let us load the packages:\n\nlibrary(MatchIt)\nlibrary(estimatr)\n\nTo estimate the propensity score, we can use the glm() command:\n\npropensity &lt;- glm(D ~ X1 + X2, data = my_data, family = \"binomial\")\nmy_data$pscore &lt;- predict(propensity, type = \"response\")\n\n\n\nReplace D with our treatment variable, and X1 and X2 with our confounders. Replace my_data with our study data.\nThen, we need to create our weights, which are the inverse of the propensity scores:\n\nmy_data$ipw &lt;- ifelse(mydata$D == 1, 1/my_data$pscore, 1/(1-my_data$pscore))\n\n\n\nReplace D with our treatment variable, and my_data with our study data.\nFinally, we need to use the lm_robust() command to estimate our causal effects:\n\nate &lt;- estimatr::lm_robust(Y ~ D, data = my_data, weights = ipw)\nsummary(ate)\n\n\n\nReplace Y with the outcome variable, D with the treatment, and my_data with our study data.\nThis will output the results, which I will show how we interpret in the next section.",
    "crumbs": [
      "Selection on Observables",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Weighting Estimator</span>"
    ]
  },
  {
    "objectID": "weighting.html#interpreting-the-results",
    "href": "weighting.html#interpreting-the-results",
    "title": "Weighting Estimator",
    "section": "Interpreting the Results",
    "text": "Interpreting the Results\nOur results will look something like this:\n\n\n\nCall:\nestimatr::lm_robust(formula = Y ~ D, data = data, weights = ipweight)\n\nWeighted, Standard error type:  HC2 \n\nCoefficients:\n            Estimate Std. Error t value   Pr(&gt;|t|) CI Lower CI Upper  DF\n(Intercept)     1.29    0.03688   34.97 1.458e-175    1.218    1.362 998\nD               1.78    0.15237   11.68  1.219e-29    1.481    2.079 998\n\nMultiple R-squared:  0.3066 ,   Adjusted R-squared:  0.3059 \nF-statistic: 136.5 on 1 and 998 DF,  p-value: &lt; 2.2e-16\n\n\nOur causal estimate is given in the coefficients table, in the D (treatment) row and Estimate column. We can see the causal effect is estimated to be 1.78. Propensity score matching estimates the ATE (see table ?tbl-estimands), so we interpret the estimate as:\n\nTreatment D on average caused a 1.4733 unit change in outcome Y.\n\n\n\n\n\n\n\nOur causal estimates are only accurate if we used all confounders in our propensity score estimation. If we forgot even just one confounder, our estimates will be wrong.\n\n\n\nIf we look at the p-value (labelled Pr(&gt;|t|)), we can see it is less than 0.05. Thus, we have a statistically significant causal effect.\n\n\nThe p-value in this outcome is written in scientific notation. You can always copy into google to see what it equals.",
    "crumbs": [
      "Selection on Observables",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Weighting Estimator</span>"
    ]
  }
]