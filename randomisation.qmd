# The Magic of Randomisation

<br />

Let us say we are interested in this question:

::: center-graph
```{dot}
//| fig-width: 4
//| fig-height: 0.45
digraph example1 {
  // Nodes
  D [shape=box, label="Scholarship (D)"]
  Y [shape=box, label="University Performance (Y)"]

  // Edges
  D -> Y [label="Causal Effect"]

  // Graph styling
  rankdir=LR; // Left to right layout
}
```
:::

Our concern is a confounder. For example, **smartness** of an individual could mean they are more likely to get a scholarship. Since smart people tend to perform well at university, that means the people who get treated are, on average, different from those who don't get treated.

::: aside
Note: smartness is not the only confounder. Other confounders could be family income, athletic ability, etc.
:::

::: center-graph
```{dot}
//| fig-width: 4
//| fig-height: 1.1
digraph example2 {
  // Nodes
  D [shape=box, pos = "0,0!", label="Scholarship (D)"]
  X [shape=box, pos = "2,0!", label="Smartness (Confounder)"]
  Y [shape=box, pos = "1,-1!", label="University Performance (Y)"]

  // Edges
  {rank=same; D -> Y [label="Causal Effect"]}
  X -> D
  X -> Y [dir=both]
  
  graph [nodesep=0.5, ranksep=0.5]

}
```
:::

The key here is that the confounder is **influencing** who gets and doesn't get the treatment.

<br />

But what if **randomness** (like flipping a coin) controls who gets the treatment or not. A coin will be flipped to decide if every person in our study will get the scholarship.

This means that the randomness (the coin), and **not the confounder**, are causing selection into treatment. So now, we have this diagram:

::: center-graph
```{dot}
//| fig-width: 4
//| fig-height: 1.1
digraph example2 {
  // Nodes
  D [shape=box, pos = "0,0!", label="Scholarship (D)"]
  X [shape=box, pos = "2,0!", label="Smartness (Confounder)"]
  Y [shape=box, pos = "1,-1!", label="University Performance (Y)"]

  // Edges
  {rank=same; D -> Y [label="Causal Effect"]}
  X -> Y [dir=both]
  
  graph [nodesep=0.5, ranksep=0.5]

}
```
:::

::: aside
Note how the confounder now no longer has an arrow to the treatment. It is no longer causing who gets the treatment or not.
:::

Since the confounder is no longer causing who gets the treatment and who doesn't, that means there is no more concern of selection bias.

<br />

Randomisation also means that since every individual has the same chance of entering treatment or control, that these two groups will be, on average, the same as each other. That means:

$$
\textcolor{purple}{\mean Y_\text{untreated}^{(0)}} = \textcolor{red}{\mean Y_\text{treated}^{(0)}}, \text{ so correlation} = \text{causation}
$$

::: aside
This equation is taken from the [last chapter](correlation.qmd).
:::

So if our treatment is randomly assigned (individuals randomly assigned to treatment or control), correlation does equal causation.

<br />

When should you use randomisation? The answer is **whenever possible**. Randomisation is the [**gold standard**]{.mark} of causal inference. There is no better method.

-   Randomisation is possible if you are running your own experiment: you can use a random number generator to assign treatment.
-   Randomisation is also possible if there is something that is being randomly assigned in the real world. For example, the US green card lottery randomly chooses who gets accepted.

<br />

However, randomisation is not always possible to do for a variety of reasons.

1.  Cost: Randomisation often involves running your own experiment.

2.  Impracticality: Sometimes it just is impossible to randomly assign certain treatments. For example, you cannot assign countries to be dictatorships in order to test the causal effect.

3.  Non-Compliance: Maybe you assign people randomly to treatment or control. But what if they don't comply with their assignment? Perhaps there is some confounder that means someone is more likely to not comply? To solve this, you will need to use **instrumental variables**.
