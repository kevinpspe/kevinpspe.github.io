# Weighting Estimator

Let us look at this example, with a confounder.

::: center-graph
```{dot}
//| fig-width: 4
//| fig-height: 1.1
digraph example2 {
  // Nodes
  D [shape=box, pos = "0,0!", label="Receiving Scholarship"]
  X [shape=box, pos = "2,0!", label="Smartness (Confounder)"]
  Y [shape=box, pos = "1,-1!", label="University Grades"]

  // Edges
  {rank=same; D -> Y [label="Causal Effect"]}
  X -> D
  X -> Y [dir=both]
  
  graph [nodesep=0.5, ranksep=0.5]

}
```
:::

::: small
Note: smartness is not the only confounder. This is for demonstration purposes.
:::

Let's pretend there are only dumb and smart people (for simplicity). Our treated and control groups might be:

|                                         |                                                   |
|-----------------------------------------|---------------------------------------------------|
| [Treated (Got Scholarship)]{.smallcaps} | [Untreated (Did not get scholarship)]{.smallcaps} |
| Smart Students (x4)                     | Smart Students (x1)                               |
| Dumb Students (x1)                      | Dumb Students (x4)                                |

: {tbl-colwidths="\[50,50\]" .bordered}

::: small
We are assuming being smarter makes you more likely to get the scholarship, since it is a confounder and should affect who gets the treatment.
:::

Our two groups have pre-existing differences. However, by emphasising certain individuals, we can make it seem like there are no more imbalances. For example, weighting might make our above table become:

|                                         |                                                   |
|-----------------------------------------|---------------------------------------------------|
| [Treated (Got Scholarship)]{.smallcaps} | [Untreated (Did not get scholarship)]{.smallcaps} |
| Smart Students (x4)                     | Smart Students (emphasise to x4)                  |
| Dumb Students (emphasise to x4)         | Dumb Students (x4)                                |

: {tbl-colwidths="\[50,50\]" .bordered}

::: small
See how the underrepresented individuals in each group (treated/untreated) were weighted upwards. More technically, inverse probability weighting emphasises/weights an individual by the inverse of their likelihood to receive treatment.
:::

We can see there is no more pre-existing differences after weighting.

::: {.callout-note appearance="minimal"}
<div>

**Kevin's Estimator Score**: <i class="fas fa-star"></i><i class="fas fa-star"></i><i class="fas fa-star"></i><i class="far fa-star"></i><i class="far fa-star"></i> (3/5)

-   Weighting is relatively good in large sample sizes.
-   **You should not use weighting when with small samples**, since their can be noticable bias, as the method is very sensitive to outlier propensity scores.
-   Weighting is more efficient with data than matching as it does not throw out unmatched observations like matching estimators do.
-   Weighting is non-parametric, so it does not assume a linear relationship like regression.

</div>
:::

Before you inverse probability weighting, make sure you have reasons to believe you meet the neccessary assumptions for selection on observables:

1.  Conditional Ignorability
2.  Common Support
3.  Stable Unit Treatment Value Assumption (SUTVA)

We will need the **MatchIt** and **estimatr** packages:

```{r, warning = F, message = F}
library(MatchIt)
library(estimatr)
```

To estimate the propensity scores and weights, we can use the **glm()** command:

```{r, eval = FALSE}
propensity <- glm(D ~ X1 + X2, data = my_data, family = "binomial")
my_data$pscore <- predict(propensity, type = "response")
my_data$ipw <- ifelse(mydata$D == 1, 1/my_data$pscore, 1/(1-my_data$pscore))
```

Finally, we need to use the **lm_robust()** command to estimate our causal effects:

```{r, eval = FALSE}
ate <- estimatr::lm_robust(Y ~ D, data = my_data, weights = ipw)
summary(ate)
```

This will output the ATT.
